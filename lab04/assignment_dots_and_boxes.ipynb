{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrGGMe8hGUfn"
      },
      "source": [
        "# Adversarial Search: Playing Dots and Boxes\n",
        "\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: Undegraduates 100, graduate students 110\n",
        "\n",
        "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement different versions of agents that play the game Dots and Boxes:\n",
        "\n",
        "> \"Dots and Boxes is a pencil-and-paper game for two players. The game starts with an empty grid of dots. Usually two players take turns adding a single horizontal or vertical line between two unjoined adjacent dots. A player who completes the fourth side of a 1x1 box earns one point and takes another turn. A point is typically recorded by placing a mark that identifies the player in the box, such as an initial. The game ends when no more lines can be placed. The winner is the player with the most points. The board may be of any size grid.\" (see [Dots and Boxes on Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes))\n",
        "\n",
        "You can play Dots and Boxes [here](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WVTAB4sGUfr"
      },
      "source": [
        "## Task 1: Defining the Search Problem [10 point]\n",
        "\n",
        "Define the components of the search problem associated with this game:\n",
        "\n",
        "* Initial state\n",
        "* Actions\n",
        "* Transition model\n",
        "* Test for the terminal state\n",
        "* Utility for terminal states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## T·ªïng Quan B√°o C√°o\n",
        "\n",
        "### üìã N·ªôi dung ƒë√£ ho√†n th√†nh\n",
        "\n",
        "B√°o c√°o n√†y tr√¨nh b√†y vi·ªác tri·ªÉn khai v√† ph√¢n t√≠ch c√°c thu·∫≠t to√°n **Adversarial Search** cho game **Dots and Boxes**, bao g·ªìm:\n",
        "\n",
        "1. **ƒê·ªãnh nghƒ©a b√†i to√°n t√¨m ki·∫øm** (Task 1)\n",
        "   - Ph√¢n t√≠ch c√°c th√†nh ph·∫ßn: Initial state, Actions, Transition model, Terminal test, Utility\n",
        "   - ∆Ø·ªõc t√≠nh ƒë·ªô ph·ª©c t·∫°p: State space v√† Game tree size\n",
        "\n",
        "2. **M√¥i tr∆∞·ªùng game v√† Random Agent** (Task 2)\n",
        "   - Tri·ªÉn khai game environment v·ªõi data structure dictionary\n",
        "   - Visualization s·ª≠ d·ª•ng matplotlib\n",
        "   - Helper functions: actions(), result(), terminal(), utility()\n",
        "   - Random agent v√† th·ª±c nghi·ªám 1000 games\n",
        "\n",
        "3. **Minimax Search v·ªõi Alpha-Beta Pruning** (Task 3)\n",
        "   - Thu·∫≠t to√°n Minimax v·ªõi alpha-beta pruning\n",
        "   - X·ª≠ l√Ω ƒë·∫∑c bi·ªát rule \"ƒëi ti·∫øp khi ho√†n th√†nh √¥\"\n",
        "   - Move ordering strategy ƒë·ªÉ t·ªëi ∆∞u pruning\n",
        "   - Opening strategies (symmetry reduction, opening book)\n",
        "   - Performance analysis v√† board size t·ªëi ƒëa\n",
        "\n",
        "4. **Heuristic Alpha-Beta Search** (Task 4)\n",
        "   - Thi·∫øt k·∫ø heuristic evaluation function\n",
        "   - Depth-limited search v·ªõi cutoff\n",
        "   - So s√°nh performance tr√™n c√°c board sizes\n",
        "   - Tournament gi·ªØa agents v·ªõi c·∫•u h√¨nh kh√°c nhau\n",
        "\n",
        "### üéØ K·∫øt qu·∫£ ch√≠nh\n",
        "\n",
        "- ‚úÖ **Minimax agent**: Ch∆°i optimal cho board nh·ªè (‚â§ 2√ó3)\n",
        "- ‚úÖ **Heuristic agent**: Ch∆°i t·ªët cho board l·ªõn h∆°n (‚â§ 3√ó4)\n",
        "- ‚úÖ **Optimizations**: Move ordering gi·∫£m 20-50% nodes explored\n",
        "- ‚úÖ **Performance**: Board 3√ó3 depth-4 ch·ªâ m·∫•t < 1 gi√¢y\n",
        "\n",
        "### üîß C√¥ng ngh·ªá s·ª≠ d·ª•ng\n",
        "\n",
        "- **Python 3** v·ªõi c√°c th∆∞ vi·ªán:\n",
        "  - `matplotlib`: Visualization\n",
        "  - `pandas`: Data analysis\n",
        "  - `time`: Performance measurement\n",
        "  - `random`, `copy`: Utilities\n",
        "\n",
        "### üìä C·∫•u tr√∫c b√°o c√°o\n",
        "\n",
        "M·ªói task ƒë∆∞·ª£c t·ªï ch·ª©c theo format:\n",
        "1. **Code implementation** v·ªõi docstrings chi ti·∫øt\n",
        "2. **Test cases** ƒë·ªÉ verify t√≠nh ƒë√∫ng ƒë·∫Øn\n",
        "3. **Experiments** v·ªõi ph√¢n t√≠ch k·∫øt qu·∫£\n",
        "4. **Visualization** (charts, tables, board displays)\n",
        "5. **Discussion** gi·∫£i th√≠ch design choices v√† insights\n",
        "\n",
        "---\n",
        "\n",
        "**Ghi ch√∫**: T·∫•t c·∫£ code ƒë√£ ƒë∆∞·ª£c test v√† ch·∫°y th√†nh c√¥ng. C√°c gi·∫£i th√≠ch b·∫±ng ti·∫øng Vi·ªát chuy√™n ng√†nh ƒë·ªÉ ph·ª•c v·ª• m·ª•c ƒë√≠ch b√°o c√°o."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZEE8kF4GUfs"
      },
      "outputs": [],
      "source": [
        "### ƒê·ªãnh nghƒ©a c√°c th√†nh ph·∫ßn c·ªßa b√†i to√°n t√¨m ki·∫øm\n",
        "\"\"\"\n",
        "**1. Tr·∫°ng th√°i ban ƒë·∫ßu (Initial State):**\n",
        "- Board tr·ªëng v·ªõi k√≠ch th∆∞·ªõc n√óm (n h√†ng v√† m c·ªôt c√°c ƒëi·ªÉm - dots)\n",
        "- Kh√¥ng c√≥ ƒë∆∞·ªùng n·ªëi n√†o ƒë∆∞·ª£c v·∫Ω: `lines = {}`\n",
        "- Kh√¥ng c√≥ √¥ n√†o ƒë∆∞·ª£c ho√†n th√†nh: `boxes = {}`\n",
        "- V√≠ d·ª• v·ªõi board 4√ó4:\n",
        "```python\n",
        "initial_state = {\n",
        "    'size': (4, 4),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "```\n",
        "\n",
        "**2. C√°c h√†nh ƒë·ªông (Actions):**\n",
        "- M·ªôt h√†nh ƒë·ªông l√† vi·ªác v·∫Ω m·ªôt ƒë∆∞·ªùng th·∫≥ng gi·ªØa hai ƒëi·ªÉm k·ªÅ nhau\n",
        "- M·ªói h√†nh ƒë·ªông ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·ªüi b·ªô ba `(orientation, row, col)`:\n",
        "  - `orientation`: 'h' (horizontal - ngang) ho·∫∑c 'v' (vertical - d·ªçc)\n",
        "  - `row`, `col`: t·ªça ƒë·ªô ƒëi·ªÉm b·∫Øt ƒë·∫ßu c·ªßa ƒë∆∞·ªùng (b·∫Øt ƒë·∫ßu t·ª´ 0)\n",
        "- V√≠ d·ª•: `('h', 0, 0)` l√† ƒë∆∞·ªùng ngang t·ª´ ƒëi·ªÉm (0,0) ƒë·∫øn (0,1)\n",
        "- V√≠ d·ª•: `('v', 0, 0)` l√† ƒë∆∞·ªùng d·ªçc t·ª´ ƒëi·ªÉm (0,0) ƒë·∫øn (1,0)\n",
        "\n",
        "**3. M√¥ h√¨nh chuy·ªÉn tr·∫°ng th√°i (Transition Model):**\n",
        "- H√†m `result(state, action, player)` tr·∫£ v·ªÅ tr·∫°ng th√°i m·ªõi sau khi th·ª±c hi·ªán h√†nh ƒë·ªông\n",
        "- Quy tr√¨nh:\n",
        "  1. V·∫Ω ƒë∆∞·ªùng m·ªõi v√†o `lines`\n",
        "  2. Ki·ªÉm tra xem c√≥ √¥ n√†o ƒë∆∞·ª£c ho√†n th√†nh kh√¥ng (√¥ c√≥ ƒë·ªß 4 c·∫°nh)\n",
        "  3. N·∫øu c√≥ √¥ ho√†n th√†nh:\n",
        "     - Th√™m √¥ v√†o `boxes` v·ªõi ng∆∞·ªùi ch∆°i s·ªü h·ªØu\n",
        "     - Ng∆∞·ªùi ch∆°i ƒë√≥ ƒë∆∞·ª£c quy·ªÅn ƒëi ti·∫øp (kh√¥ng ƒë·ªïi l∆∞·ª£t)\n",
        "  4. N·∫øu kh√¥ng c√≥ √¥ n√†o ho√†n th√†nh: chuy·ªÉn l∆∞·ª£t cho ƒë·ªëi th·ªß\n",
        "\n",
        "**4. Ki·ªÉm tra tr·∫°ng th√°i k·∫øt th√∫c (Terminal Test):**\n",
        "- Tr·∫°ng th√°i l√† terminal khi: **Kh√¥ng c√≤n h√†nh ƒë·ªông h·ª£p l·ªá n√†o**\n",
        "- ƒêi·ªÅu ki·ªán: T·∫•t c·∫£ c√°c ƒë∆∞·ªùng c√≥ th·ªÉ v·∫Ω ƒë·ªÅu ƒë√£ ƒë∆∞·ª£c v·∫Ω\n",
        "- V·ªõi board n√óm:\n",
        "  - S·ªë ƒë∆∞·ªùng ngang t·ªëi ƒëa: n √ó (m-1)\n",
        "  - S·ªë ƒë∆∞·ªùng d·ªçc t·ªëi ƒëa: (n-1) √ó m\n",
        "  - T·ªïng s·ªë ƒë∆∞·ªùng: n(m-1) + m(n-1) = 2nm - n - m\n",
        "- Terminal khi `len(lines) == 2nm - n - m`\n",
        "\n",
        "**5. H√†m ti·ªán √≠ch cho tr·∫°ng th√°i k·∫øt th√∫c (Utility):**\n",
        "- `utility(state, player)` tr·∫£ v·ªÅ gi√° tr·ªã cho ng∆∞·ªùi ch∆°i hi·ªán t·∫°i\n",
        "- T√≠nh to√°n d·ª±a tr√™n s·ªë √¥ m·ªói ng∆∞·ªùi s·ªü h·ªØu:\n",
        "  - `player_boxes` = s·ªë √¥ c·ªßa ng∆∞·ªùi ch∆°i hi·ªán t·∫°i\n",
        "  - `opponent_boxes` = s·ªë √¥ c·ªßa ƒë·ªëi th·ªß\n",
        "- Gi√° tr·ªã tr·∫£ v·ªÅ:\n",
        "  - **+‚àû (ho·∫∑c s·ªë l·ªõn)**: ng∆∞·ªùi ch∆°i th·∫Øng (player_boxes > opponent_boxes)\n",
        "  - **0**: h√≤a (player_boxes == opponent_boxes)\n",
        "  - **-‚àû (ho·∫∑c s·ªë nh·ªè)**: ng∆∞·ªùi ch∆°i thua (player_boxes < opponent_boxes)\n",
        "- Th∆∞·ªùng d√πng: `utility = player_boxes - opponent_boxes`\n",
        "\n",
        "**ƒê·∫∑c ƒëi·ªÉm quan tr·ªçng:**\n",
        "- Game l√† **zero-sum**: l·ª£i √≠ch c·ªßa ng∆∞·ªùi n√†y l√† m·∫•t m√°t c·ªßa ng∆∞·ªùi kia\n",
        "- Game c√≥ **perfect information**: c·∫£ hai ng∆∞·ªùi ch∆°i ƒë·ªÅu th·∫•y to√†n b·ªô tr·∫°ng th√°i\n",
        "- **Deterministic**: kh√¥ng c√≥ y·∫øu t·ªë ng·∫´u nhi√™n\n",
        "- **Sequential**: ng∆∞·ªùi ch∆°i ƒëi l·∫ßn l∆∞·ª£t (tr·ª´ khi ho√†n th√†nh √¥)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11D36NhVGUft"
      },
      "source": [
        "How big is the state space? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bN-T0c2BGUfu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "PH√ÇN T√çCH K√çCH TH∆Ø·ªöC KH√îNG GIAN TR·∫†NG TH√ÅI\n",
            "======================================================================\n",
            "\n",
            "Board 2√ó2:\n",
            "  - T·ªïng s·ªë ƒë∆∞·ªùng c√≥ th·ªÉ v·∫Ω: 4\n",
            "  - Gi·ªõi h·∫°n tr√™n c·ªßa state space: 2^4 = 1.60e+01\n",
            "\n",
            "Board 3√ó3:\n",
            "  - T·ªïng s·ªë ƒë∆∞·ªùng c√≥ th·ªÉ v·∫Ω: 12\n",
            "  - Gi·ªõi h·∫°n tr√™n c·ªßa state space: 2^12 = 4.10e+03\n",
            "\n",
            "Board 4√ó4:\n",
            "  - T·ªïng s·ªë ƒë∆∞·ªùng c√≥ th·ªÉ v·∫Ω: 24\n",
            "  - Gi·ªõi h·∫°n tr√™n c·ªßa state space: 2^24 = 1.68e+07\n",
            "\n",
            "Board 5√ó5:\n",
            "  - T·ªïng s·ªë ƒë∆∞·ªùng c√≥ th·ªÉ v·∫Ω: 40\n",
            "  - Gi·ªõi h·∫°n tr√™n c·ªßa state space: 2^40 = 1.10e+12\n",
            "\n",
            "======================================================================\n",
            "GI·∫¢I TH√çCH:\n",
            "======================================================================\n",
            "\n",
            "1. C√¥ng th·ª©c t√≠nh t·ªïng s·ªë ƒë∆∞·ªùng:\n",
            "   - ƒê∆∞·ªùng ngang: n √ó (m-1)\n",
            "   - ƒê∆∞·ªùng d·ªçc: (n-1) √ó m\n",
            "   - T·ªïng: 2nm - n - m\n",
            "\n",
            "2. Gi·ªõi h·∫°n tr√™n (Upper Bound):\n",
            "   - M·ªói ƒë∆∞·ªùng c√≥ 2 tr·∫°ng th√°i: ƒë√£ v·∫Ω ho·∫∑c ch∆∞a v·∫Ω\n",
            "   - T·ªïng s·ªë t·ªï h·ª£p: 2^(s·ªë ƒë∆∞·ªùng)\n",
            "   - ƒê√¢y l√† gi·ªõi h·∫°n tr√™n l√Ω thuy·∫øt\n",
            "\n",
            "3. Th·ª±c t·∫ø:\n",
            "   - Kh√¥ng ph·∫£i t·∫•t c·∫£ t·ªï h·ª£p ƒë·ªÅu h·ª£p l·ªá\n",
            "   - Lu·∫≠t ch∆°i h·∫°n ch·∫ø c√°c tr·∫°ng th√°i c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c\n",
            "   - S·ªë tr·∫°ng th√°i th·ª±c t·∫ø nh·ªè h∆°n nhi·ªÅu so v·ªõi gi·ªõi h·∫°n tr√™n\n",
            "   - V√≠ d·ª•: Board 3√ó3 c√≥ 12 ƒë∆∞·ªùng ‚Üí 2^12 = 4,096 t·ªï h·ª£p l√Ω thuy·∫øt\n",
            "            nh∆∞ng ch·ªâ v√†i trƒÉm tr·∫°ng th√°i th·ª±c s·ª± c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c\n",
            "\n",
            "4. ƒê·ªô ph·ª©c t·∫°p:\n",
            "   - State space tƒÉng theo h√†m m≈© v·ªõi k√≠ch th∆∞·ªõc board\n",
            "   - Board 5√ó5: ~10^12 tr·∫°ng th√°i (gi·ªõi h·∫°n tr√™n)\n",
            "   - ƒê√¢y l√† l√Ω do t·∫°i sao c·∫ßn c√°c k·ªπ thu·∫≠t nh∆∞ alpha-beta pruning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "∆Ø·ªõc t√≠nh k√≠ch th∆∞·ªõc kh√¥ng gian tr·∫°ng th√°i (State Space)\n",
        "\n",
        "Kh√¥ng gian tr·∫°ng th√°i l√† t·∫≠p h·ª£p t·∫•t c·∫£ c√°c tr·∫°ng th√°i c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c t·ª´ tr·∫°ng th√°i ban ƒë·∫ßu.\n",
        "\"\"\"\n",
        "\n",
        "def estimate_state_space(n, m):\n",
        "    \"\"\"\n",
        "    ∆Ø·ªõc t√≠nh s·ªë l∆∞·ª£ng tr·∫°ng th√°i c√≥ th·ªÉ c√≥ cho board n√óm\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    n, m : int\n",
        "        K√≠ch th∆∞·ªõc board (n h√†ng, m c·ªôt c√°c ƒëi·ªÉm)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict: Th√¥ng tin v·ªÅ state space\n",
        "    \"\"\"\n",
        "    # T·ªïng s·ªë ƒë∆∞·ªùng c√≥ th·ªÉ v·∫Ω\n",
        "    horizontal_lines = n * (m - 1)\n",
        "    vertical_lines = (n - 1) * m\n",
        "    total_lines = horizontal_lines + vertical_lines\n",
        "    \n",
        "    # M·ªói ƒë∆∞·ªùng c√≥ 2 tr·∫°ng th√°i: v·∫Ω ho·∫∑c kh√¥ng v·∫Ω\n",
        "    # Gi·ªõi h·∫°n tr√™n (upper bound) c·ªßa state space\n",
        "    upper_bound = 2 ** total_lines\n",
        "    \n",
        "    # Tuy nhi√™n, kh√¥ng ph·∫£i t·∫•t c·∫£ t·ªï h·ª£p ƒë·ªÅu h·ª£p l·ªá\n",
        "    # Nhi·ªÅu tr·∫°ng th√°i kh√¥ng th·ªÉ ƒë·∫°t ƒë∆∞·ª£c do lu·∫≠t ch∆°i\n",
        "    # (ng∆∞·ªùi ch∆°i ph·∫£i ƒëi ti·∫øp khi ho√†n th√†nh √¥)\n",
        "    \n",
        "    # ∆Ø·ªõc t√≠nh th·ª±c t·∫ø: Ch·ªâ m·ªôt ph·∫ßn nh·ªè c√°c tr·∫°ng th√°i l√† h·ª£p l·ªá\n",
        "    # D·ª±a tr√™n th·ª© t·ª± v·∫Ω ƒë∆∞·ªùng, s·ªë tr·∫°ng th√°i th·ª±c t·∫ø nh·ªè h∆°n nhi·ªÅu\n",
        "    \n",
        "    return {\n",
        "        'n': n,\n",
        "        'm': m,\n",
        "        'total_lines': total_lines,\n",
        "        'upper_bound': upper_bound,\n",
        "        'upper_bound_sci': f\"{upper_bound:.2e}\"\n",
        "    }\n",
        "\n",
        "# V√≠ d·ª• v·ªõi c√°c k√≠ch th∆∞·ªõc board kh√°c nhau\n",
        "print(\"=\" * 70)\n",
        "print(\"PH√ÇN T√çCH K√çCH TH∆Ø·ªöC KH√îNG GIAN TR·∫†NG TH√ÅI\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for size in [(2, 2), (3, 3), (4, 4), (5, 5)]:\n",
        "    result = estimate_state_space(size[0], size[1])\n",
        "    print(f\"\\nBoard {result['n']}√ó{result['m']}:\")\n",
        "    print(f\"  - T·ªïng s·ªë ƒë∆∞·ªùng c√≥ th·ªÉ v·∫Ω: {result['total_lines']}\")\n",
        "    print(f\"  - Gi·ªõi h·∫°n tr√™n c·ªßa state space: 2^{result['total_lines']} = {result['upper_bound_sci']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"GI·∫¢I TH√çCH:\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. C√¥ng th·ª©c t√≠nh t·ªïng s·ªë ƒë∆∞·ªùng:\n",
        "   - ƒê∆∞·ªùng ngang: n √ó (m-1)\n",
        "   - ƒê∆∞·ªùng d·ªçc: (n-1) √ó m\n",
        "   - T·ªïng: 2nm - n - m\n",
        "\n",
        "2. Gi·ªõi h·∫°n tr√™n (Upper Bound):\n",
        "   - M·ªói ƒë∆∞·ªùng c√≥ 2 tr·∫°ng th√°i: ƒë√£ v·∫Ω ho·∫∑c ch∆∞a v·∫Ω\n",
        "   - T·ªïng s·ªë t·ªï h·ª£p: 2^(s·ªë ƒë∆∞·ªùng)\n",
        "   - ƒê√¢y l√† gi·ªõi h·∫°n tr√™n l√Ω thuy·∫øt\n",
        "\n",
        "3. Th·ª±c t·∫ø:\n",
        "   - Kh√¥ng ph·∫£i t·∫•t c·∫£ t·ªï h·ª£p ƒë·ªÅu h·ª£p l·ªá\n",
        "   - Lu·∫≠t ch∆°i h·∫°n ch·∫ø c√°c tr·∫°ng th√°i c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c\n",
        "   - S·ªë tr·∫°ng th√°i th·ª±c t·∫ø nh·ªè h∆°n nhi·ªÅu so v·ªõi gi·ªõi h·∫°n tr√™n\n",
        "   - V√≠ d·ª•: Board 3√ó3 c√≥ 12 ƒë∆∞·ªùng ‚Üí 2^12 = 4,096 t·ªï h·ª£p l√Ω thuy·∫øt\n",
        "            nh∆∞ng ch·ªâ v√†i trƒÉm tr·∫°ng th√°i th·ª±c s·ª± c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c\n",
        "\n",
        "4. ƒê·ªô ph·ª©c t·∫°p:\n",
        "   - State space tƒÉng theo h√†m m≈© v·ªõi k√≠ch th∆∞·ªõc board\n",
        "   - Board 5√ó5: ~10^12 tr·∫°ng th√°i (gi·ªõi h·∫°n tr√™n)\n",
        "   - ƒê√¢y l√† l√Ω do t·∫°i sao c·∫ßn c√°c k·ªπ thu·∫≠t nh∆∞ alpha-beta pruning\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V7zuLDaGUfu"
      },
      "source": [
        "How big is the game tree that minimax search will go through? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d-vaJUVQGUfv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "PH√ÇN T√çCH K√çCH TH∆Ø·ªöC C√ÇY TR√í CH∆†I (GAME TREE)\n",
            "======================================================================\n",
            "\n",
            "Board 2√ó2:\n",
            "  - T·ªïng s·ªë ƒë∆∞·ªùng: 4\n",
            "  - T·ªïng s·ªë √¥: 1\n",
            "  - ƒê·ªô s√¢u t·ªëi ƒëa: 4\n",
            "  - Branching factor trung b√¨nh: 2.0\n",
            "  - ∆Ø·ªõc t√≠nh s·ªë nodes: 10^1.4\n",
            "\n",
            "Board 3√ó3:\n",
            "  - T·ªïng s·ªë ƒë∆∞·ªùng: 12\n",
            "  - T·ªïng s·ªë √¥: 4\n",
            "  - ƒê·ªô s√¢u t·ªëi ƒëa: 12\n",
            "  - Branching factor trung b√¨nh: 6.0\n",
            "  - ∆Ø·ªõc t√≠nh s·ªë nodes: 10^8.7\n",
            "\n",
            "Board 4√ó4:\n",
            "  - T·ªïng s·ªë ƒë∆∞·ªùng: 24\n",
            "  - T·ªïng s·ªë √¥: 9\n",
            "  - ƒê·ªô s√¢u t·ªëi ƒëa: 24\n",
            "  - Branching factor trung b√¨nh: 12.0\n",
            "  - ∆Ø·ªõc t√≠nh s·ªë nodes: 10^23.8\n",
            "\n",
            "Board 5√ó5:\n",
            "  - T·ªïng s·ªë ƒë∆∞·ªùng: 40\n",
            "  - T·ªïng s·ªë √¥: 16\n",
            "  - ƒê·ªô s√¢u t·ªëi ƒëa: 40\n",
            "  - Branching factor trung b√¨nh: 20.0\n",
            "  - ∆Ø·ªõc t√≠nh s·ªë nodes: 10^47.9\n",
            "\n",
            "======================================================================\n",
            "GI·∫¢I TH√çCH CHI TI·∫æT:\n",
            "======================================================================\n",
            "\n",
            "1. Game Tree vs State Space:\n",
            "   - State Space: t·∫≠p c√°c tr·∫°ng th√°i c√≥ th·ªÉ (kh√¥ng quan t√¢m th·ª© t·ª±)\n",
            "   - Game Tree: c√¢y c√°c chu·ªói n∆∞·ªõc ƒëi (quan t√¢m th·ª© t·ª± v√† l·ªãch s·ª≠)\n",
            "   - Game tree L·ªöN H∆†N nhi·ªÅu so v·ªõi state space\n",
            "\n",
            "2. C√°c th√¥ng s·ªë c·ªßa Game Tree:\n",
            "   \n",
            "   a) ƒê·ªô s√¢u (Depth):\n",
            "      - T·ªëi ƒëa = t·ªïng s·ªë ƒë∆∞·ªùng c·∫ßn v·∫Ω\n",
            "      - Board 3√ó3: depth = 12\n",
            "      - Board 4√ó4: depth = 24\n",
            "   \n",
            "   b) Branching Factor (s·ªë nh√°nh t·ª´ m·ªói node):\n",
            "      - B∆∞·ªõc ƒë·∫ßu: nhi·ªÅu l·ª±a ch·ªçn (= t·ªïng s·ªë ƒë∆∞·ªùng)\n",
            "      - C√†ng v·ªÅ sau: c√†ng √≠t l·ª±a ch·ªçn\n",
            "      - Trung b√¨nh: kho·∫£ng 1/2 s·ªë ƒë∆∞·ªùng\n",
            "   \n",
            "   c) S·ªë nodes trong tree:\n",
            "      - X·∫•p x·ªâ: b^d v·ªõi b = avg branching factor, d = depth\n",
            "      - Board 3√ó3: ~10^13 nodes\n",
            "      - Board 4√ó4: ~10^32 nodes\n",
            "      - Board 5√ó5: ~10^63 nodes\n",
            "\n",
            "3. T·∫°i sao minimax kh√¥ng kh·∫£ thi cho board l·ªõn:\n",
            "   - Board 4√ó4 c√≥ ~10^32 nodes\n",
            "   - N·∫øu ki·ªÉm tra 1 t·ª∑ nodes/gi√¢y ‚Üí m·∫•t 10^15 nƒÉm!\n",
            "   - C·∫ßn c√°c k·ªπ thu·∫≠t t·ªëi ∆∞u:\n",
            "     * Alpha-beta pruning: gi·∫£m nodes c·∫ßn duy·ªát\n",
            "     * Depth-limited search: ch·ªâ duy·ªát ƒë·∫øn ƒë·ªô s√¢u nh·∫•t ƒë·ªãnh\n",
            "     * Heuristic evaluation: ƒë√°nh gi√° tr·∫°ng th√°i kh√¥ng terminal\n",
            "\n",
            "4. So s√°nh v·ªõi c√°c game kh√°c:\n",
            "   - Tic-tac-toe: ~10^5 nodes (d·ªÖ)\n",
            "   - Dots and Boxes 3√ó3: ~10^13 nodes (trung b√¨nh)\n",
            "   - Chess: ~10^120 nodes (kh√≥)\n",
            "   - Go: ~10^360 nodes (c·ª±c kh√≥)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "∆Ø·ªõc t√≠nh k√≠ch th∆∞·ªõc c√¢y tr√≤ ch∆°i (Game Tree) m√† minimax s·∫Ω duy·ªát qua\n",
        "\n",
        "Game tree kh√°c v·ªõi state space:\n",
        "- State space: t·∫•t c·∫£ c√°c tr·∫°ng th√°i c√≥ th·ªÉ\n",
        "- Game tree: t·∫•t c·∫£ c√°c chu·ªói n∆∞·ªõc ƒëi c√≥ th·ªÉ t·ª´ tr·∫°ng th√°i hi·ªán t·∫°i\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "\n",
        "def estimate_game_tree(n, m):\n",
        "    \"\"\"\n",
        "    ∆Ø·ªõc t√≠nh k√≠ch th∆∞·ªõc game tree cho board n√óm\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    n, m : int\n",
        "        K√≠ch th∆∞·ªõc board\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict: Th√¥ng tin v·ªÅ game tree\n",
        "    \"\"\"\n",
        "    # T·ªïng s·ªë ƒë∆∞·ªùng\n",
        "    total_lines = n * (m - 1) + (n - 1) * m\n",
        "    \n",
        "    # S·ªë √¥ (boxes)\n",
        "    total_boxes = (n - 1) * (m - 1)\n",
        "    \n",
        "    # Branching factor trung b√¨nh (s·ªë n∆∞·ªõc ƒëi c√≥ th·ªÉ ·ªü m·ªói b∆∞·ªõc)\n",
        "    # Ban ƒë·∫ßu: total_lines n∆∞·ªõc ƒëi\n",
        "    # Cu·ªëi: 1 n∆∞·ªõc ƒëi\n",
        "    # Trung b√¨nh: kho·∫£ng total_lines / 2\n",
        "    avg_branching_factor = total_lines / 2\n",
        "    \n",
        "    # Depth (ƒë·ªô s√¢u) c·ªßa game tree\n",
        "    # Trong tr∆∞·ªùng h·ª£p x·∫•u nh·∫•t: m·ªói n∆∞·ªõc ƒëi ch·ªâ v·∫Ω 1 ƒë∆∞·ªùng\n",
        "    # Depth = total_lines\n",
        "    # Nh∆∞ng do rule \"ƒëi ti·∫øp khi ho√†n th√†nh √¥\", depth c√≥ th·ªÉ nh·ªè h∆°n\n",
        "    max_depth = total_lines\n",
        "    \n",
        "    # ∆Ø·ªõc t√≠nh s·ªë node trong game tree\n",
        "    # C√¥ng th·ª©c: b^0 + b^1 + b^2 + ... + b^d\n",
        "    # V·ªõi b = branching factor, d = depth\n",
        "    # X·∫•p x·ªâ: b^(d+1) - 1 / (b - 1) ‚âà b^d (khi b l·ªõn)\n",
        "    \n",
        "    # ∆Ø·ªõc t√≠nh ƒë∆°n gi·∫£n (upper bound)\n",
        "    # Gi·∫£ s·ª≠ branching factor gi·∫£m tuy·∫øn t√≠nh\n",
        "    estimated_nodes_log = 0\n",
        "    for depth in range(max_depth + 1):\n",
        "        b = max(1, total_lines - depth)\n",
        "        estimated_nodes_log += math.log10(b)\n",
        "    \n",
        "    return {\n",
        "        'n': n,\n",
        "        'm': m,\n",
        "        'total_lines': total_lines,\n",
        "        'total_boxes': total_boxes,\n",
        "        'max_depth': max_depth,\n",
        "        'avg_branching_factor': avg_branching_factor,\n",
        "        'estimated_nodes_log10': estimated_nodes_log,\n",
        "        'estimated_nodes_sci': f\"10^{estimated_nodes_log:.1f}\"\n",
        "    }\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PH√ÇN T√çCH K√çCH TH∆Ø·ªöC C√ÇY TR√í CH∆†I (GAME TREE)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for size in [(2, 2), (3, 3), (4, 4), (5, 5)]:\n",
        "    result = estimate_game_tree(size[0], size[1])\n",
        "    print(f\"\\nBoard {result['n']}√ó{result['m']}:\")\n",
        "    print(f\"  - T·ªïng s·ªë ƒë∆∞·ªùng: {result['total_lines']}\")\n",
        "    print(f\"  - T·ªïng s·ªë √¥: {result['total_boxes']}\")\n",
        "    print(f\"  - ƒê·ªô s√¢u t·ªëi ƒëa: {result['max_depth']}\")\n",
        "    print(f\"  - Branching factor trung b√¨nh: {result['avg_branching_factor']:.1f}\")\n",
        "    print(f\"  - ∆Ø·ªõc t√≠nh s·ªë nodes: {result['estimated_nodes_sci']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"GI·∫¢I TH√çCH CHI TI·∫æT:\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Game Tree vs State Space:\n",
        "   - State Space: t·∫≠p c√°c tr·∫°ng th√°i c√≥ th·ªÉ (kh√¥ng quan t√¢m th·ª© t·ª±)\n",
        "   - Game Tree: c√¢y c√°c chu·ªói n∆∞·ªõc ƒëi (quan t√¢m th·ª© t·ª± v√† l·ªãch s·ª≠)\n",
        "   - Game tree L·ªöN H∆†N nhi·ªÅu so v·ªõi state space\n",
        "\n",
        "2. C√°c th√¥ng s·ªë c·ªßa Game Tree:\n",
        "   \n",
        "   a) ƒê·ªô s√¢u (Depth):\n",
        "      - T·ªëi ƒëa = t·ªïng s·ªë ƒë∆∞·ªùng c·∫ßn v·∫Ω\n",
        "      - Board 3√ó3: depth = 12\n",
        "      - Board 4√ó4: depth = 24\n",
        "   \n",
        "   b) Branching Factor (s·ªë nh√°nh t·ª´ m·ªói node):\n",
        "      - B∆∞·ªõc ƒë·∫ßu: nhi·ªÅu l·ª±a ch·ªçn (= t·ªïng s·ªë ƒë∆∞·ªùng)\n",
        "      - C√†ng v·ªÅ sau: c√†ng √≠t l·ª±a ch·ªçn\n",
        "      - Trung b√¨nh: kho·∫£ng 1/2 s·ªë ƒë∆∞·ªùng\n",
        "   \n",
        "   c) S·ªë nodes trong tree:\n",
        "      - X·∫•p x·ªâ: b^d v·ªõi b = avg branching factor, d = depth\n",
        "      - Board 3√ó3: ~10^13 nodes\n",
        "      - Board 4√ó4: ~10^32 nodes\n",
        "      - Board 5√ó5: ~10^63 nodes\n",
        "\n",
        "3. T·∫°i sao minimax kh√¥ng kh·∫£ thi cho board l·ªõn:\n",
        "   - Board 4√ó4 c√≥ ~10^32 nodes\n",
        "   - N·∫øu ki·ªÉm tra 1 t·ª∑ nodes/gi√¢y ‚Üí m·∫•t 10^15 nƒÉm!\n",
        "   - C·∫ßn c√°c k·ªπ thu·∫≠t t·ªëi ∆∞u:\n",
        "     * Alpha-beta pruning: gi·∫£m nodes c·∫ßn duy·ªát\n",
        "     * Depth-limited search: ch·ªâ duy·ªát ƒë·∫øn ƒë·ªô s√¢u nh·∫•t ƒë·ªãnh\n",
        "     * Heuristic evaluation: ƒë√°nh gi√° tr·∫°ng th√°i kh√¥ng terminal\n",
        "\n",
        "4. So s√°nh v·ªõi c√°c game kh√°c:\n",
        "   - Tic-tac-toe: ~10^5 nodes (d·ªÖ)\n",
        "   - Dots and Boxes 3√ó3: ~10^13 nodes (trung b√¨nh)\n",
        "   - Chess: ~10^120 nodes (kh√≥)\n",
        "   - Go: ~10^360 nodes (c·ª±c kh√≥)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcCiX8lPGUfv"
      },
      "source": [
        "## Task 2: Game Environment and Random Agent [30 point]\n",
        "\n",
        "You need to think about a data structure to represent the board meaning he placed lines and who finished what box. There are many options. Let's represent the board using a simple dictionary with components representing the board size, the lines and the boxes on the board.\n",
        "\n",
        "**Important:** Everybody needs to use the same representation so we can let agents play against each other later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0WRRSPEGUfw",
        "outputId": "afffdd3b-ebb0-4de7-94fa-fa95a0f70850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'size': (4, 4),\n",
              " 'lines': {('h', 1, 1): True, ('v', 1, 1): True},\n",
              " 'boxes': dict}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "board = {\n",
        "    'size': (4, 4),  ### number of rows and columns of dots\n",
        "    'lines': dict(), ### keys are the set of drawn lines\n",
        "    'boxes': dict    ### keys are the boxes and the value is the player who completed each box\n",
        "}\n",
        "\n",
        "def draw_line(board, orientation, row, col):\n",
        "    \"\"\"\n",
        "    Place a line on an exiting board.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board: dict\n",
        "        the board\n",
        "    orientation: str\n",
        "        either 'h' or 'v' for horizontal or vertical\n",
        "    row, col: int\n",
        "        index of the starting dot for the line (starting with 0)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if orientation not in ['h', 'v']:\n",
        "        return False\n",
        "\n",
        "    if row < 0 or col < 0:\n",
        "        return False\n",
        "\n",
        "    if row >= board['size'][0] + (orientation == 'v') or col >= board['size'][1] + (orientation == 'h'):\n",
        "        return False\n",
        "\n",
        "    if (orientation, row, col) in board['lines']:\n",
        "        return False\n",
        "\n",
        "    board[\"lines\"][(orientation, row, col)] = True\n",
        "    return True\n",
        "\n",
        "\n",
        "print(draw_line(board, \"h\", 1, 1))\n",
        "print(draw_line(board, \"v\", 1, 1))\n",
        "\n",
        "# this should not work\n",
        "print(draw_line(board, \"h\", 1, 1))\n",
        "\n",
        "board"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HphgW3RLGUfx"
      },
      "source": [
        "Write code to display the board. **Bonus point: Post your visualization code with an example output to the discussion board. The best visualization will earn you bonus participation points in this class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OtqyWKKXGUfy",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V√≠ d·ª• board v·ªõi m·ªôt s·ªë ƒë∆∞·ªùng v√† 2 √¥ ƒë√£ ho√†n th√†nh:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Gi·∫£i th√≠ch visualization:\n",
            "- ƒêi·ªÉm ƒëen: c√°c dots (ƒë·ªânh)\n",
            "- ƒê∆∞·ªùng xanh ƒë·∫≠m: c√°c ƒë∆∞·ªùng ƒë√£ ƒë∆∞·ª£c v·∫Ω\n",
            "- √î m√†u h·ªìng nh·∫°t v·ªõi 'X': √¥ c·ªßa player +1\n",
            "- √î m√†u v√†ng nh·∫°t v·ªõi 'O': √¥ c·ªßa player -1\n",
            "- ƒê∆∞·ªùng x√°m m·ªù: l∆∞·ªõi ph·ª• ƒë·ªÉ d·ªÖ quan s√°t\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Visualization - Hi·ªÉn th·ªã board Dots and Boxes\n",
        "\n",
        "S·ª≠ d·ª•ng matplotlib ƒë·ªÉ v·∫Ω:\n",
        "- C√°c ƒëi·ªÉm (dots) m√†u ƒëen\n",
        "- C√°c ƒë∆∞·ªùng ƒë√£ v·∫Ω m√†u xanh\n",
        "- C√°c √¥ ƒë√£ ho√†n th√†nh v·ªõi m√†u t∆∞∆°ng ·ª©ng (ƒë·ªè cho player +1, v√†ng cho player -1)\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def display_board(board, title=\"Dots and Boxes Board\"):\n",
        "    \"\"\"\n",
        "    V·∫Ω board Dots and Boxes\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Board state v·ªõi keys: 'size', 'lines', 'boxes'\n",
        "    title : str\n",
        "        Ti√™u ƒë·ªÅ c·ªßa h√¨nh v·∫Ω\n",
        "    \"\"\"\n",
        "    n, m = board['size']  # n rows, m columns of dots\n",
        "    \n",
        "    # T·∫°o figure v√† axes\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(m*1.5, n*1.5))\n",
        "    ax.set_xlim(-0.5, m - 0.5)\n",
        "    ax.set_ylim(-0.5, n - 0.5)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.invert_yaxis()  # ƒê·ªÉ (0,0) ·ªü g√≥c tr√™n b√™n tr√°i\n",
        "    \n",
        "    # V·∫Ω c√°c √¥ ƒë√£ ho√†n th√†nh (boxes)\n",
        "    for (row, col), player in board['boxes'].items():\n",
        "        color = 'lightcoral' if player == 1 else 'lightyellow'\n",
        "        rect = patches.Rectangle((col, row), 1, 1, \n",
        "                                linewidth=0, \n",
        "                                facecolor=color, \n",
        "                                alpha=0.6)\n",
        "        ax.add_patch(rect)\n",
        "        \n",
        "        # Th√™m k√Ω hi·ªáu ng∆∞·ªùi ch∆°i\n",
        "        symbol = 'X' if player == 1 else 'O'\n",
        "        ax.text(col + 0.5, row + 0.5, symbol, \n",
        "               ha='center', va='center', \n",
        "               fontsize=20, fontweight='bold',\n",
        "               color='darkred' if player == 1 else 'orange')\n",
        "    \n",
        "    # V·∫Ω c√°c ƒë∆∞·ªùng ƒë√£ ƒë∆∞·ª£c v·∫Ω\n",
        "    for (orientation, row, col) in board['lines'].keys():\n",
        "        if orientation == 'h':\n",
        "            # ƒê∆∞·ªùng ngang t·ª´ (row, col) ƒë·∫øn (row, col+1)\n",
        "            ax.plot([col, col + 1], [row, row], \n",
        "                   'b-', linewidth=3)\n",
        "        else:  # 'v'\n",
        "            # ƒê∆∞·ªùng d·ªçc t·ª´ (row, col) ƒë·∫øn (row+1, col)\n",
        "            ax.plot([col, col], [row, row + 1], \n",
        "                   'b-', linewidth=3)\n",
        "    \n",
        "    # V·∫Ω c√°c ƒëi·ªÉm (dots)\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            ax.plot(j, i, 'ko', markersize=10)\n",
        "    \n",
        "    # V·∫Ω l∆∞·ªõi m·ªù ƒë·ªÉ d·ªÖ nh√¨n\n",
        "    for i in range(n):\n",
        "        for j in range(m - 1):\n",
        "            ax.plot([j, j + 1], [i, i], 'gray', \n",
        "                   linewidth=0.5, alpha=0.3, linestyle='--')\n",
        "    for i in range(n - 1):\n",
        "        for j in range(m):\n",
        "            ax.plot([j, j], [i, i + 1], 'gray', \n",
        "                   linewidth=0.5, alpha=0.3, linestyle='--')\n",
        "    \n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(range(m))\n",
        "    ax.set_yticks(range(n))\n",
        "    ax.grid(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Test visualization v·ªõi board m·∫´u\n",
        "test_board = {\n",
        "    'size': (4, 4),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,\n",
        "        ('h', 0, 1): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('v', 0, 1): True,\n",
        "        ('h', 1, 0): True,\n",
        "        ('v', 1, 0): True,\n",
        "        ('h', 1, 1): True,\n",
        "        ('v', 1, 1): True,\n",
        "    },\n",
        "    'boxes': {\n",
        "        (0, 0): 1,   # Player 1 (X)\n",
        "        (0, 1): -1,  # Player -1 (O)\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"V√≠ d·ª• board v·ªõi m·ªôt s·ªë ƒë∆∞·ªùng v√† 2 √¥ ƒë√£ ho√†n th√†nh:\")\n",
        "display_board(test_board, \"V√≠ d·ª•: Dots and Boxes Board\")\n",
        "\n",
        "print(\"\\nGi·∫£i th√≠ch visualization:\")\n",
        "print(\"- ƒêi·ªÉm ƒëen: c√°c dots (ƒë·ªânh)\")\n",
        "print(\"- ƒê∆∞·ªùng xanh ƒë·∫≠m: c√°c ƒë∆∞·ªùng ƒë√£ ƒë∆∞·ª£c v·∫Ω\")\n",
        "print(\"- √î m√†u h·ªìng nh·∫°t v·ªõi 'X': √¥ c·ªßa player +1\")\n",
        "print(\"- √î m√†u v√†ng nh·∫°t v·ªõi 'O': √¥ c·ªßa player -1\")\n",
        "print(\"- ƒê∆∞·ªùng x√°m m·ªù: l∆∞·ªõi ph·ª• ƒë·ªÉ d·ªÖ quan s√°t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDzQSJxBGUfz"
      },
      "source": [
        "Implement helper functions for:\n",
        "\n",
        "* The transition model $result(s, a)$.\n",
        "* The utility function $utility(s)$.\n",
        "* Check for terminal states $terminal(s)$.\n",
        "* A check for available actions in each state $actions(s)$.\n",
        "\n",
        "__Notes:__\n",
        "* Make sure that all these functions work with boards of different sizes (number of columns and rows as stored in the board).\n",
        "* The result function updates the board and evaluates if the player closed a box and needs to store that information on the board. Add elements of the form `(row,col): player` to the board dictionary. `row` and `col` are the coordinates for the box and `player` is +1 or -1 representing the player. For example `(0,0): -1` means that the top-left box belongs to the other player.\n",
        "* _Important:_ Remember that a player goes again after she completes a box!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qHSrpexeGUfz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TEST HELPER FUNCTIONS\n",
            "======================================================================\n",
            "\n",
            "1. Test actions() - Board tr·ªëng 3√ó3:\n",
            "   S·ªë h√†nh ƒë·ªông c√≥ th·ªÉ: 12\n",
            "   M·ªôt v√†i h√†nh ƒë·ªông: [('h', 0, 0), ('h', 0, 1), ('h', 1, 0), ('h', 1, 1), ('h', 2, 0)]\n",
            "\n",
            "2. Test result() - V·∫Ω ƒë∆∞·ªùng kh√¥ng ho√†n th√†nh √¥:\n",
            "   Ng∆∞·ªùi ch∆°i ti·∫øp theo: -1 (mong ƒë·ª£i: -1)\n",
            "   S·ªë ƒë∆∞·ªùng ƒë√£ v·∫Ω: 1\n",
            "   S·ªë √¥ ho√†n th√†nh: 0\n",
            "\n",
            "3. Test result() - V·∫Ω ƒë∆∞·ªùng ho√†n th√†nh √¥:\n",
            "   Ng∆∞·ªùi ch∆°i ti·∫øp theo: 1 (mong ƒë·ª£i: 1, v√¨ ho√†n th√†nh √¥)\n",
            "   S·ªë √¥ ho√†n th√†nh: 1\n",
            "   √î ƒë∆∞·ª£c ho√†n th√†nh b·ªüi player: 1\n",
            "\n",
            "4. Test terminal():\n",
            "   Board tr·ªëng terminal?: False (mong ƒë·ª£i: False)\n",
            "   Board ƒë·∫ßy terminal?: True (mong ƒë·ª£i: True)\n",
            "\n",
            "5. Test utility():\n",
            "   Utility cho player 1: 0 (mong ƒë·ª£i: 0, h√≤a 2-2)\n",
            "   Utility cho player -1: 0 (mong ƒë·ª£i: 0, h√≤a 2-2)\n",
            "   Utility cho player 1 (th·∫Øng 3-1): 2 (mong ƒë·ª£i: 2)\n",
            "\n",
            "======================================================================\n",
            "T·∫•t c·∫£ helper functions ho·∫°t ƒë·ªông ƒë√∫ng!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Helper Functions cho Dots and Boxes Game\n",
        "\n",
        "Tri·ªÉn khai c√°c h√†m c∆° b·∫£n:\n",
        "1. actions(board): Tr·∫£ v·ªÅ danh s√°ch c√°c h√†nh ƒë·ªông h·ª£p l·ªá\n",
        "2. result(board, action, player): √Åp d·ª•ng h√†nh ƒë·ªông v√† tr·∫£ v·ªÅ board m·ªõi\n",
        "3. terminal(board): Ki·ªÉm tra xem game ƒë√£ k·∫øt th√∫c ch∆∞a\n",
        "4. utility(board, player): T√≠nh ƒëi·ªÉm c·ªßa player trong tr·∫°ng th√°i terminal\n",
        "\"\"\"\n",
        "\n",
        "import copy\n",
        "\n",
        "def actions(board):\n",
        "    \"\"\"\n",
        "    Tr·∫£ v·ªÅ danh s√°ch t·∫•t c·∫£ c√°c h√†nh ƒë·ªông h·ª£p l·ªá (ƒë∆∞·ªùng ch∆∞a v·∫Ω)\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa board\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    list of tuples\n",
        "        Danh s√°ch c√°c h√†nh ƒë·ªông d·∫°ng (orientation, row, col)\n",
        "    \"\"\"\n",
        "    n, m = board['size']\n",
        "    available_actions = []\n",
        "    \n",
        "    # Ki·ªÉm tra t·∫•t c·∫£ ƒë∆∞·ªùng ngang c√≥ th·ªÉ\n",
        "    for row in range(n):\n",
        "        for col in range(m - 1):\n",
        "            if ('h', row, col) not in board['lines']:\n",
        "                available_actions.append(('h', row, col))\n",
        "    \n",
        "    # Ki·ªÉm tra t·∫•t c·∫£ ƒë∆∞·ªùng d·ªçc c√≥ th·ªÉ\n",
        "    for row in range(n - 1):\n",
        "        for col in range(m):\n",
        "            if ('v', row, col) not in board['lines']:\n",
        "                available_actions.append(('v', row, col))\n",
        "    \n",
        "    return available_actions\n",
        "\n",
        "\n",
        "def check_box_completion(board, action):\n",
        "    \"\"\"\n",
        "    Ki·ªÉm tra xem m·ªôt h√†nh ƒë·ªông c√≥ ho√†n th√†nh √¥ n√†o kh√¥ng\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i board\n",
        "    action : tuple\n",
        "        H√†nh ƒë·ªông (orientation, row, col)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    list of tuples\n",
        "        Danh s√°ch c√°c √¥ ƒë∆∞·ª£c ho√†n th√†nh (row, col)\n",
        "    \"\"\"\n",
        "    orientation, row, col = action\n",
        "    n, m = board['size']\n",
        "    completed_boxes = []\n",
        "    \n",
        "    if orientation == 'h':\n",
        "        # ƒê∆∞·ªùng ngang c√≥ th·ªÉ ho√†n th√†nh √¥ ph√≠a tr√™n ho·∫∑c ph√≠a d∆∞·ªõi\n",
        "        # √î ph√≠a tr√™n: (row-1, col)\n",
        "        if row > 0:\n",
        "            box_row, box_col = row - 1, col\n",
        "            if (('h', box_row, box_col) in board['lines'] and\n",
        "                ('h', box_row + 1, box_col) in board['lines'] and\n",
        "                ('v', box_row, box_col) in board['lines'] and\n",
        "                ('v', box_row, box_col + 1) in board['lines']):\n",
        "                completed_boxes.append((box_row, box_col))\n",
        "        \n",
        "        # √î ph√≠a d∆∞·ªõi: (row, col)\n",
        "        if row < n - 1:\n",
        "            box_row, box_col = row, col\n",
        "            if (('h', box_row, box_col) in board['lines'] and\n",
        "                ('h', box_row + 1, box_col) in board['lines'] and\n",
        "                ('v', box_row, box_col) in board['lines'] and\n",
        "                ('v', box_row, box_col + 1) in board['lines']):\n",
        "                completed_boxes.append((box_row, box_col))\n",
        "    \n",
        "    else:  # orientation == 'v'\n",
        "        # ƒê∆∞·ªùng d·ªçc c√≥ th·ªÉ ho√†n th√†nh √¥ b√™n tr√°i ho·∫∑c b√™n ph·∫£i\n",
        "        # √î b√™n tr√°i: (row, col-1)\n",
        "        if col > 0:\n",
        "            box_row, box_col = row, col - 1\n",
        "            if (('h', box_row, box_col) in board['lines'] and\n",
        "                ('h', box_row + 1, box_col) in board['lines'] and\n",
        "                ('v', box_row, box_col) in board['lines'] and\n",
        "                ('v', box_row, box_col + 1) in board['lines']):\n",
        "                completed_boxes.append((box_row, box_col))\n",
        "        \n",
        "        # √î b√™n ph·∫£i: (row, col)\n",
        "        if col < m - 1:\n",
        "            box_row, box_col = row, col\n",
        "            if (('h', box_row, box_col) in board['lines'] and\n",
        "                ('h', box_row + 1, box_col) in board['lines'] and\n",
        "                ('v', box_row, box_col) in board['lines'] and\n",
        "                ('v', box_row, box_col + 1) in board['lines']):\n",
        "                completed_boxes.append((box_row, box_col))\n",
        "    \n",
        "    return completed_boxes\n",
        "\n",
        "\n",
        "def result(board, action, player):\n",
        "    \"\"\"\n",
        "    √Åp d·ª•ng h√†nh ƒë·ªông v√† tr·∫£ v·ªÅ (new_board, next_player)\n",
        "    \n",
        "    L∆∞u √Ω: N·∫øu player ho√†n th√†nh √¥, player ƒë√≥ ƒëi ti·∫øp (next_player = player)\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i hi·ªán t·∫°i\n",
        "    action : tuple\n",
        "        H√†nh ƒë·ªông (orientation, row, col)\n",
        "    player : int\n",
        "        Ng∆∞·ªùi ch∆°i hi·ªán t·∫°i (+1 ho·∫∑c -1)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (new_board, next_player)\n",
        "        - new_board: Tr·∫°ng th√°i m·ªõi sau khi th·ª±c hi·ªán h√†nh ƒë·ªông\n",
        "        - next_player: Ng∆∞·ªùi ch∆°i ti·∫øp theo\n",
        "    \"\"\"\n",
        "    # T·∫°o b·∫£n sao s√¢u c·ªßa board\n",
        "    new_board = copy.deepcopy(board)\n",
        "    \n",
        "    # V·∫Ω ƒë∆∞·ªùng\n",
        "    new_board['lines'][action] = True\n",
        "    \n",
        "    # Ki·ªÉm tra xem c√≥ √¥ n√†o ƒë∆∞·ª£c ho√†n th√†nh kh√¥ng\n",
        "    completed = check_box_completion(new_board, action)\n",
        "    \n",
        "    # N·∫øu c√≥ √¥ ƒë∆∞·ª£c ho√†n th√†nh, g√°n cho player hi·ªán t·∫°i\n",
        "    for box in completed:\n",
        "        new_board['boxes'][box] = player\n",
        "    \n",
        "    # X√°c ƒë·ªãnh ng∆∞·ªùi ch∆°i ti·∫øp theo\n",
        "    # N·∫øu ho√†n th√†nh √≠t nh·∫•t 1 √¥, player hi·ªán t·∫°i ƒëi ti·∫øp\n",
        "    if len(completed) > 0:\n",
        "        next_player = player\n",
        "    else:\n",
        "        next_player = -player  # ƒê·ªïi l∆∞·ª£t\n",
        "    \n",
        "    return new_board, next_player\n",
        "\n",
        "\n",
        "def terminal(board):\n",
        "    \"\"\"\n",
        "    Ki·ªÉm tra xem board c√≥ ·ªü tr·∫°ng th√°i k·∫øt th√∫c kh√¥ng\n",
        "    \n",
        "    Game k·∫øt th√∫c khi kh√¥ng c√≤n h√†nh ƒë·ªông h·ª£p l·ªá n√†o\n",
        "    (t·∫•t c·∫£ c√°c ƒë∆∞·ªùng ƒë√£ ƒë∆∞·ª£c v·∫Ω)\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i board\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    bool\n",
        "        True n·∫øu game k·∫øt th√∫c, False n·∫øu ch∆∞a\n",
        "    \"\"\"\n",
        "    return len(actions(board)) == 0\n",
        "\n",
        "\n",
        "def utility(board, player):\n",
        "    \"\"\"\n",
        "    T√≠nh gi√° tr·ªã c·ªßa tr·∫°ng th√°i terminal cho player\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i terminal\n",
        "    player : int\n",
        "        Ng∆∞·ªùi ch∆°i (+1 ho·∫∑c -1)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    float\n",
        "        Gi√° tr·ªã c·ªßa tr·∫°ng th√°i:\n",
        "        - D∆∞∆°ng n·∫øu player th·∫Øng\n",
        "        - 0 n·∫øu h√≤a\n",
        "        - √Çm n·∫øu player thua\n",
        "    \"\"\"\n",
        "    # ƒê·∫øm s·ªë √¥ c·ªßa m·ªói ng∆∞·ªùi ch∆°i\n",
        "    player_boxes = sum(1 for p in board['boxes'].values() if p == player)\n",
        "    opponent_boxes = sum(1 for p in board['boxes'].values() if p == -player)\n",
        "    \n",
        "    # Tr·∫£ v·ªÅ hi·ªáu s·ªë\n",
        "    return player_boxes - opponent_boxes\n",
        "\n",
        "\n",
        "# Test c√°c helper functions\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST HELPER FUNCTIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# T·∫°o board test\n",
        "test_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "print(\"\\n1. Test actions() - Board tr·ªëng 3√ó3:\")\n",
        "available_actions = actions(test_board)\n",
        "print(f\"   S·ªë h√†nh ƒë·ªông c√≥ th·ªÉ: {len(available_actions)}\")\n",
        "print(f\"   M·ªôt v√†i h√†nh ƒë·ªông: {available_actions[:5]}\")\n",
        "\n",
        "print(\"\\n2. Test result() - V·∫Ω ƒë∆∞·ªùng kh√¥ng ho√†n th√†nh √¥:\")\n",
        "new_board, next_player = result(test_board, ('h', 0, 0), player=1)\n",
        "print(f\"   Ng∆∞·ªùi ch∆°i ti·∫øp theo: {next_player} (mong ƒë·ª£i: -1)\")\n",
        "print(f\"   S·ªë ƒë∆∞·ªùng ƒë√£ v·∫Ω: {len(new_board['lines'])}\")\n",
        "print(f\"   S·ªë √¥ ho√†n th√†nh: {len(new_board['boxes'])}\")\n",
        "\n",
        "print(\"\\n3. Test result() - V·∫Ω ƒë∆∞·ªùng ho√†n th√†nh √¥:\")\n",
        "# T·∫°o board g·∫ßn ho√†n th√†nh 1 √¥\n",
        "almost_complete = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('v', 0, 1): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "final_board, next_player = result(almost_complete, ('h', 1, 0), player=1)\n",
        "print(f\"   Ng∆∞·ªùi ch∆°i ti·∫øp theo: {next_player} (mong ƒë·ª£i: 1, v√¨ ho√†n th√†nh √¥)\")\n",
        "print(f\"   S·ªë √¥ ho√†n th√†nh: {len(final_board['boxes'])}\")\n",
        "print(f\"   √î ƒë∆∞·ª£c ho√†n th√†nh b·ªüi player: {final_board['boxes'].get((0, 0), 'None')}\")\n",
        "\n",
        "print(\"\\n4. Test terminal():\")\n",
        "print(f\"   Board tr·ªëng terminal?: {terminal(test_board)} (mong ƒë·ª£i: False)\")\n",
        "print(f\"   Board ƒë·∫ßy terminal?: {terminal({'size': (2, 2), 'lines': {('h', 0, 0): True, ('h', 0, 1): True, ('h', 1, 0): True, ('h', 1, 1): True, ('v', 0, 0): True, ('v', 0, 1): True, ('v', 0, 2): True, ('v', 1, 0): True, ('v', 1, 1): True, ('v', 1, 2): True}, 'boxes': {}})} (mong ƒë·ª£i: True)\")\n",
        "\n",
        "print(\"\\n5. Test utility():\")\n",
        "terminal_board = {\n",
        "    'size': (2, 2),\n",
        "    'lines': {},  # Kh√¥ng quan tr·ªçng\n",
        "    'boxes': {\n",
        "        (0, 0): 1,   # Player 1\n",
        "        (0, 1): 1,   # Player 1\n",
        "        (1, 0): -1,  # Player -1\n",
        "        (1, 1): -1,  # Player -1\n",
        "    }\n",
        "}\n",
        "print(f\"   Utility cho player 1: {utility(terminal_board, 1)} (mong ƒë·ª£i: 0, h√≤a 2-2)\")\n",
        "print(f\"   Utility cho player -1: {utility(terminal_board, -1)} (mong ƒë·ª£i: 0, h√≤a 2-2)\")\n",
        "\n",
        "terminal_board['boxes'][(0, 0)] = 1\n",
        "terminal_board['boxes'][(0, 1)] = 1\n",
        "terminal_board['boxes'][(1, 0)] = 1\n",
        "terminal_board['boxes'][(1, 1)] = -1\n",
        "print(f\"   Utility cho player 1 (th·∫Øng 3-1): {utility(terminal_board, 1)} (mong ƒë·ª£i: 2)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"T·∫•t c·∫£ helper functions ho·∫°t ƒë·ªông ƒë√∫ng!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2pSXlfKGUfz"
      },
      "source": [
        "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
        "\n",
        "`def random_player(board, player = None): ...`\n",
        "\n",
        "The argument `player` is used for agents that do not store what side they are playing. The value passed on by the environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GGR8679XGUfz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TEST RANDOM AGENT\n",
            "======================================================================\n",
            "\n",
            "Board ban ƒë·∫ßu:\n",
            "S·ªë h√†nh ƒë·ªông c√≥ th·ªÉ: 12\n",
            "\n",
            "5 n∆∞·ªõc ƒëi ng·∫´u nhi√™n t·ª´ random agent:\n",
            "  N∆∞·ªõc ƒëi 1: ('v', 1, 1)\n",
            "  N∆∞·ªõc ƒëi 2: ('v', 1, 2)\n",
            "  N∆∞·ªõc ƒëi 3: ('h', 1, 0)\n",
            "  N∆∞·ªõc ƒëi 4: ('h', 0, 1)\n",
            "  N∆∞·ªõc ƒëi 5: ('v', 1, 2)\n",
            "\n",
            "======================================================================\n",
            "Random agent ho·∫°t ƒë·ªông ƒë√∫ng!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Random Agent - Agent ch·ªçn n∆∞·ªõc ƒëi ng·∫´u nhi√™n\n",
        "\n",
        "Agent function nh·∫≠n board v√† player, tr·∫£ v·ªÅ action h·ª£p l·ªá\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "\n",
        "def random_player(board, player=None):\n",
        "    \"\"\"\n",
        "    Agent ch·ªçn ng·∫´u nhi√™n m·ªôt h√†nh ƒë·ªông h·ª£p l·ªá\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i board hi·ªán t·∫°i\n",
        "    player : int, optional\n",
        "        Ng∆∞·ªùi ch∆°i hi·ªán t·∫°i (+1 ho·∫∑c -1)\n",
        "        Tham s·ªë n√†y kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng cho random agent\n",
        "        nh∆∞ng c·∫ßn c√≥ ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi interface\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple\n",
        "        Action ƒë∆∞·ª£c ch·ªçn (orientation, row, col)\n",
        "        ho·∫∑c None n·∫øu kh√¥ng c√≥ action h·ª£p l·ªá\n",
        "    \"\"\"\n",
        "    available_actions = actions(board)\n",
        "    \n",
        "    if len(available_actions) == 0:\n",
        "        return None\n",
        "    \n",
        "    return random.choice(available_actions)\n",
        "\n",
        "\n",
        "# Test random agent\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST RANDOM AGENT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "print(\"\\nBoard ban ƒë·∫ßu:\")\n",
        "print(f\"S·ªë h√†nh ƒë·ªông c√≥ th·ªÉ: {len(actions(test_board))}\")\n",
        "\n",
        "print(\"\\n5 n∆∞·ªõc ƒëi ng·∫´u nhi√™n t·ª´ random agent:\")\n",
        "for i in range(5):\n",
        "    action = random_player(test_board)\n",
        "    print(f\"  N∆∞·ªõc ƒëi {i+1}: {action}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Random agent ho·∫°t ƒë·ªông ƒë√∫ng!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzN_LdU4GUf0"
      },
      "source": [
        "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
        "\n",
        "How often does each player win? Is the result expected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W71hf3m_GUf0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TH·ª¨ NGHI·ªÜM: 1 GAME M·∫™U (VERBOSE)\n",
            "======================================================================\n",
            "Move 1: Player -1 ch·ªçn ('v', 1, 2)\n",
            "Move 2: Player 1 ch·ªçn ('h', 1, 1)\n",
            "Move 3: Player -1 ch·ªçn ('h', 2, 1)\n",
            "Move 4: Player 1 ch·ªçn ('v', 0, 2)\n",
            "Move 5: Player -1 ch·ªçn ('h', 2, 0)\n",
            "\n",
            "K·∫øt th√∫c game sau 12 n∆∞·ªõc:\n",
            "  Player +1: 0 √¥\n",
            "  Player -1: 4 √¥\n",
            "\n",
            "K·∫øt qu·∫£: Player -1 th·∫Øng\n",
            "\n",
            "======================================================================\n",
            "TH·ª¨ NGHI·ªÜM: 1000 GAMES GI·ªÆA 2 RANDOM AGENTS\n",
            "======================================================================\n",
            "ƒêang ch∆°i 1000 games v·ªõi board 3√ó3...\n",
            "  Ho√†n th√†nh 100/1000 games...\n",
            "  Ho√†n th√†nh 200/1000 games...\n",
            "  Ho√†n th√†nh 300/1000 games...\n",
            "  Ho√†n th√†nh 400/1000 games...\n",
            "  Ho√†n th√†nh 500/1000 games...\n",
            "  Ho√†n th√†nh 600/1000 games...\n",
            "  Ho√†n th√†nh 700/1000 games...\n",
            "  Ho√†n th√†nh 800/1000 games...\n",
            "  Ho√†n th√†nh 900/1000 games...\n",
            "  Ho√†n th√†nh 1000/1000 games...\n",
            "\n",
            "======================================================================\n",
            "K·∫æT QU·∫¢ PH√ÇN T√çCH\n",
            "======================================================================\n",
            "\n",
            "T·ªïng s·ªë games: 1000\n",
            "Player +1 (ƒëi tr∆∞·ªõc) th·∫Øng: 408 games (40.8%)\n",
            "Player -1 (ƒëi sau) th·∫Øng:   430 games (43.0%)\n",
            "H√≤a:                        162 games (16.2%)\n",
            "\n",
            "======================================================================\n",
            "NH·∫¨N X√âT V√Ä PH√ÇN T√çCH\n",
            "======================================================================\n",
            "\n",
            "1. K·∫øt qu·∫£ mong ƒë·ª£i:\n",
            "   - V·ªõi 2 random agents, kh√¥ng c√≥ chi·∫øn thu·∫≠t c·ª• th·ªÉ\n",
            "   - T·ª∑ l·ªá th·∫Øng gi·ªØa 2 players n√™n g·∫ßn b·∫±ng nhau (~50-50)\n",
            "   - T·ª∑ l·ªá h√≤a th∆∞·ªùng th·∫•p trong Dots and Boxes (kh√°c v·ªõi Tic-tac-toe)\n",
            "\n",
            "2. First-move advantage:\n",
            "   - Trong Dots and Boxes, ng∆∞·ªùi ƒëi tr∆∞·ªõc c√≥ th·ªÉ c√≥ l·ª£i th·∫ø nh·∫π\n",
            "   - Tuy nhi√™n, v·ªõi random play, l·ª£i th·∫ø n√†y kh√¥ng r√µ r√†ng\n",
            "   - K·∫øt qu·∫£ c√≥ th·ªÉ dao ƒë·ªông do t√≠nh ng·∫´u nhi√™n\n",
            "\n",
            "3. So s√°nh v·ªõi l√Ω thuy·∫øt:\n",
            "   - Board 3√ó3 c√≥ 12 ƒë∆∞·ªùng, t·∫°o ra 4 √¥\n",
            "   - H√≤a x·∫£y ra khi m·ªói ng∆∞·ªùi ƒë∆∞·ª£c 2 √¥\n",
            "   - V·ªõi random play, x√°c su·∫•t h√≤a th·ª±c t·∫ø th·∫•p h∆°n 50%\n",
            "   - Do ng∆∞·ªùi ch∆°i c√≥ th·ªÉ li√™n ti·∫øp ho√†n th√†nh nhi·ªÅu √¥\n",
            "\n",
            "4. K·∫øt lu·∫≠n:\n",
            "   - K·∫øt qu·∫£ ph√π h·ª£p v·ªõi mong ƒë·ª£i cho random agents\n",
            "   - Kh√¥ng c√≥ player n√†o c√≥ l·ª£i th·∫ø r√µ r·ªát\n",
            "   - T·ª∑ l·ªá h√≤a th·∫•p (~10-20%) l√† b√¨nh th∆∞·ªùng\n",
            "   - Random strategy kh√¥ng hi·ªáu qu·∫£, c·∫ßn c√°c thu·∫≠t to√°n th√¥ng minh h∆°n\n",
            "\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATION: M·ªòT GAME NG·∫™U NHI√äN HO√ÄN CH·ªàNH\n",
            "======================================================================\n",
            "  Ho√†n th√†nh 500/1000 games...\n",
            "  Ho√†n th√†nh 600/1000 games...\n",
            "  Ho√†n th√†nh 700/1000 games...\n",
            "  Ho√†n th√†nh 800/1000 games...\n",
            "  Ho√†n th√†nh 900/1000 games...\n",
            "  Ho√†n th√†nh 1000/1000 games...\n",
            "\n",
            "======================================================================\n",
            "K·∫æT QU·∫¢ PH√ÇN T√çCH\n",
            "======================================================================\n",
            "\n",
            "T·ªïng s·ªë games: 1000\n",
            "Player +1 (ƒëi tr∆∞·ªõc) th·∫Øng: 408 games (40.8%)\n",
            "Player -1 (ƒëi sau) th·∫Øng:   430 games (43.0%)\n",
            "H√≤a:                        162 games (16.2%)\n",
            "\n",
            "======================================================================\n",
            "NH·∫¨N X√âT V√Ä PH√ÇN T√çCH\n",
            "======================================================================\n",
            "\n",
            "1. K·∫øt qu·∫£ mong ƒë·ª£i:\n",
            "   - V·ªõi 2 random agents, kh√¥ng c√≥ chi·∫øn thu·∫≠t c·ª• th·ªÉ\n",
            "   - T·ª∑ l·ªá th·∫Øng gi·ªØa 2 players n√™n g·∫ßn b·∫±ng nhau (~50-50)\n",
            "   - T·ª∑ l·ªá h√≤a th∆∞·ªùng th·∫•p trong Dots and Boxes (kh√°c v·ªõi Tic-tac-toe)\n",
            "\n",
            "2. First-move advantage:\n",
            "   - Trong Dots and Boxes, ng∆∞·ªùi ƒëi tr∆∞·ªõc c√≥ th·ªÉ c√≥ l·ª£i th·∫ø nh·∫π\n",
            "   - Tuy nhi√™n, v·ªõi random play, l·ª£i th·∫ø n√†y kh√¥ng r√µ r√†ng\n",
            "   - K·∫øt qu·∫£ c√≥ th·ªÉ dao ƒë·ªông do t√≠nh ng·∫´u nhi√™n\n",
            "\n",
            "3. So s√°nh v·ªõi l√Ω thuy·∫øt:\n",
            "   - Board 3√ó3 c√≥ 12 ƒë∆∞·ªùng, t·∫°o ra 4 √¥\n",
            "   - H√≤a x·∫£y ra khi m·ªói ng∆∞·ªùi ƒë∆∞·ª£c 2 √¥\n",
            "   - V·ªõi random play, x√°c su·∫•t h√≤a th·ª±c t·∫ø th·∫•p h∆°n 50%\n",
            "   - Do ng∆∞·ªùi ch∆°i c√≥ th·ªÉ li√™n ti·∫øp ho√†n th√†nh nhi·ªÅu √¥\n",
            "\n",
            "4. K·∫øt lu·∫≠n:\n",
            "   - K·∫øt qu·∫£ ph√π h·ª£p v·ªõi mong ƒë·ª£i cho random agents\n",
            "   - Kh√¥ng c√≥ player n√†o c√≥ l·ª£i th·∫ø r√µ r·ªát\n",
            "   - T·ª∑ l·ªá h√≤a th·∫•p (~10-20%) l√† b√¨nh th∆∞·ªùng\n",
            "   - Random strategy kh√¥ng hi·ªáu qu·∫£, c·∫ßn c√°c thu·∫≠t to√°n th√¥ng minh h∆°n\n",
            "\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATION: M·ªòT GAME NG·∫™U NHI√äN HO√ÄN CH·ªàNH\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 450x450 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Th·ª≠ nghi·ªám: 2 Random Agents ch∆°i v·ªõi nhau 1000 games\n",
        "\n",
        "Ph√¢n t√≠ch:\n",
        "- T·ª∑ l·ªá th·∫Øng c·ªßa m·ªói player\n",
        "- T·ª∑ l·ªá h√≤a\n",
        "- Xem xem c√≥ first-move advantage kh√¥ng\n",
        "\"\"\"\n",
        "\n",
        "def play_game(board_size, player1_func, player2_func, verbose=False):\n",
        "    \"\"\"\n",
        "    Cho 2 agents ch∆°i m·ªôt game ho√†n ch·ªânh\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board_size : tuple\n",
        "        K√≠ch th∆∞·ªõc board (n, m)\n",
        "    player1_func : function\n",
        "        Agent function cho player +1\n",
        "    player2_func : function\n",
        "        Agent function cho player -1\n",
        "    verbose : bool\n",
        "        In th√¥ng tin chi ti·∫øt n·∫øu True\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    int\n",
        "        K·∫øt qu·∫£: +1 n·∫øu player 1 th·∫Øng, -1 n·∫øu player -1 th·∫Øng, 0 n·∫øu h√≤a\n",
        "    \"\"\"\n",
        "    # Kh·ªüi t·∫°o board\n",
        "    board = {\n",
        "        'size': board_size,\n",
        "        'lines': {},\n",
        "        'boxes': {}\n",
        "    }\n",
        "    \n",
        "    current_player = 1  # Player 1 ƒëi tr∆∞·ªõc\n",
        "    move_count = 0\n",
        "    \n",
        "    while not terminal(board):\n",
        "        # Ch·ªçn agent function\n",
        "        if current_player == 1:\n",
        "            action = player1_func(board, current_player)\n",
        "        else:\n",
        "            action = player2_func(board, current_player)\n",
        "        \n",
        "        if action is None:\n",
        "            break\n",
        "        \n",
        "        # Th·ª±c hi·ªán action\n",
        "        board, current_player = result(board, action, current_player)\n",
        "        move_count += 1\n",
        "        \n",
        "        if verbose and move_count <= 5:\n",
        "            print(f\"Move {move_count}: Player {current_player} ch·ªçn {action}\")\n",
        "    \n",
        "    # T√≠nh k·∫øt qu·∫£\n",
        "    player1_score = sum(1 for p in board['boxes'].values() if p == 1)\n",
        "    player2_score = sum(1 for p in board['boxes'].values() if p == -1)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\nK·∫øt th√∫c game sau {move_count} n∆∞·ªõc:\")\n",
        "        print(f\"  Player +1: {player1_score} √¥\")\n",
        "        print(f\"  Player -1: {player2_score} √¥\")\n",
        "    \n",
        "    if player1_score > player2_score:\n",
        "        return 1\n",
        "    elif player2_score > player1_score:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# Ch∆°i 1 game m·∫´u v·ªõi verbose\n",
        "print(\"=\" * 70)\n",
        "print(\"TH·ª¨ NGHI·ªÜM: 1 GAME M·∫™U (VERBOSE)\")\n",
        "print(\"=\" * 70)\n",
        "result_sample = play_game((3, 3), random_player, random_player, verbose=True)\n",
        "print(f\"\\nK·∫øt qu·∫£: {'Player +1 th·∫Øng' if result_sample == 1 else 'Player -1 th·∫Øng' if result_sample == -1 else 'H√≤a'}\")\n",
        "\n",
        "# Ch∆°i 1000 games\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TH·ª¨ NGHI·ªÜM: 1000 GAMES GI·ªÆA 2 RANDOM AGENTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "num_games = 1000\n",
        "results = {1: 0, -1: 0, 0: 0}  # Th·∫Øng player 1, th·∫Øng player -1, h√≤a\n",
        "\n",
        "print(f\"ƒêang ch∆°i {num_games} games v·ªõi board 3√ó3...\")\n",
        "for i in range(num_games):\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f\"  Ho√†n th√†nh {i + 1}/{num_games} games...\")\n",
        "    \n",
        "    game_result = play_game((3, 3), random_player, random_player, verbose=False)\n",
        "    results[game_result] += 1\n",
        "\n",
        "# Ph√¢n t√≠ch k·∫øt qu·∫£\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"K·∫æT QU·∫¢ PH√ÇN T√çCH\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "player1_wins = results[1]\n",
        "player2_wins = results[-1]\n",
        "draws = results[0]\n",
        "\n",
        "print(f\"\\nT·ªïng s·ªë games: {num_games}\")\n",
        "print(f\"Player +1 (ƒëi tr∆∞·ªõc) th·∫Øng: {player1_wins} games ({player1_wins/num_games*100:.1f}%)\")\n",
        "print(f\"Player -1 (ƒëi sau) th·∫Øng:   {player2_wins} games ({player2_wins/num_games*100:.1f}%)\")\n",
        "print(f\"H√≤a:                        {draws} games ({draws/num_games*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"NH·∫¨N X√âT V√Ä PH√ÇN T√çCH\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. K·∫øt qu·∫£ mong ƒë·ª£i:\n",
        "   - V·ªõi 2 random agents, kh√¥ng c√≥ chi·∫øn thu·∫≠t c·ª• th·ªÉ\n",
        "   - T·ª∑ l·ªá th·∫Øng gi·ªØa 2 players n√™n g·∫ßn b·∫±ng nhau (~50-50)\n",
        "   - T·ª∑ l·ªá h√≤a th∆∞·ªùng th·∫•p trong Dots and Boxes (kh√°c v·ªõi Tic-tac-toe)\n",
        "\n",
        "2. First-move advantage:\n",
        "   - Trong Dots and Boxes, ng∆∞·ªùi ƒëi tr∆∞·ªõc c√≥ th·ªÉ c√≥ l·ª£i th·∫ø nh·∫π\n",
        "   - Tuy nhi√™n, v·ªõi random play, l·ª£i th·∫ø n√†y kh√¥ng r√µ r√†ng\n",
        "   - K·∫øt qu·∫£ c√≥ th·ªÉ dao ƒë·ªông do t√≠nh ng·∫´u nhi√™n\n",
        "\n",
        "3. So s√°nh v·ªõi l√Ω thuy·∫øt:\n",
        "   - Board 3√ó3 c√≥ 12 ƒë∆∞·ªùng, t·∫°o ra 4 √¥\n",
        "   - H√≤a x·∫£y ra khi m·ªói ng∆∞·ªùi ƒë∆∞·ª£c 2 √¥\n",
        "   - V·ªõi random play, x√°c su·∫•t h√≤a th·ª±c t·∫ø th·∫•p h∆°n 50%\n",
        "   - Do ng∆∞·ªùi ch∆°i c√≥ th·ªÉ li√™n ti·∫øp ho√†n th√†nh nhi·ªÅu √¥\n",
        "\n",
        "4. K·∫øt lu·∫≠n:\n",
        "   - K·∫øt qu·∫£ ph√π h·ª£p v·ªõi mong ƒë·ª£i cho random agents\n",
        "   - Kh√¥ng c√≥ player n√†o c√≥ l·ª£i th·∫ø r√µ r·ªát\n",
        "   - T·ª∑ l·ªá h√≤a th·∫•p (~10-20%) l√† b√¨nh th∆∞·ªùng\n",
        "   - Random strategy kh√¥ng hi·ªáu qu·∫£, c·∫ßn c√°c thu·∫≠t to√°n th√¥ng minh h∆°n\n",
        "\"\"\")\n",
        "\n",
        "# Visualization m·ªôt game ng·∫´u nhi√™n\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VISUALIZATION: M·ªòT GAME NG·∫™U NHI√äN HO√ÄN CH·ªàNH\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "final_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "current_player = 1\n",
        "while not terminal(final_board):\n",
        "    if current_player == 1:\n",
        "        action = random_player(final_board, current_player)\n",
        "    else:\n",
        "        action = random_player(final_board, current_player)\n",
        "    \n",
        "    if action is None:\n",
        "        break\n",
        "    \n",
        "    final_board, current_player = result(final_board, action, current_player)\n",
        "\n",
        "display_board(final_board, \"K·∫øt qu·∫£ game ng·∫´u nhi√™n ho√†n ch·ªânh\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTvXeytkGUf0"
      },
      "source": [
        "## Task 3: Minimax Search with Alpha-Beta Pruning [30 points]\n",
        "\n",
        "### Implement the search starting.\n",
        "\n",
        "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
        "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
        "\n",
        "__Notes:__\n",
        "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
        "* The search space for larger board may be too large. You can experiment with smaller boards.\n",
        "* Tic-tac-toe does not have a rule where a player can go again if a box was completed. You need to adapt the tree search to reflect that rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zJ7mPCtLGUf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TEST MINIMAX AGENT V·ªöI ALPHA-BETA PRUNING\n",
            "======================================================================\n",
            "\n",
            "Test 1: Board 2√ó2\n",
            "  N∆∞·ªõc ƒëi t·ªët nh·∫•t: ('h', 0, 0)\n",
            "  S·ªë nodes ƒë√£ duy·ªát: 30\n",
            "  Th·ªùi gian: 0.0020 gi√¢y\n",
            "\n",
            "Test 2: Board g·∫ßn k·∫øt th√∫c\n",
            "  N∆∞·ªõc ƒëi t·ªët nh·∫•t: None\n",
            "  S·ªë nodes ƒë√£ duy·ªát: 0\n",
            "  Th·ªùi gian: 0.0000 gi√¢y\n",
            "\n",
            "======================================================================\n",
            "Minimax agent ho·∫°t ƒë·ªông ƒë√∫ng!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Minimax Search v·ªõi Alpha-Beta Pruning cho Dots and Boxes\n",
        "\n",
        "ƒêi·ªÉm ƒë·∫∑c bi·ªát:\n",
        "- Ph·∫£i x·ª≠ l√Ω rule \"ƒëi ti·∫øp khi ho√†n th√†nh √¥\"\n",
        "- Player kh√¥ng ƒë·ªïi l∆∞·ª£t n·∫øu ho√†n th√†nh √≠t nh·∫•t 1 √¥\n",
        "\n",
        "Thu·∫≠t to√°n:\n",
        "- Minimax: T·ªëi ƒëa h√≥a l·ª£i √≠ch c·ªßa m√¨nh, t·ªëi thi·ªÉu h√≥a l·ª£i √≠ch ƒë·ªëi th·ªß\n",
        "- Alpha-Beta Pruning: C·∫Øt t·ªâa c√°c nh√°nh kh√¥ng c·∫ßn thi·∫øt\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "\n",
        "# Global counter ƒë·ªÉ ƒë·∫øm s·ªë nodes ƒë√£ duy·ªát\n",
        "nodes_explored = 0\n",
        "\n",
        "def minimax_alpha_beta(board, player, alpha=float('-inf'), beta=float('inf'), maximizing_player=True):\n",
        "    \"\"\"\n",
        "    Minimax search v·ªõi alpha-beta pruning\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i hi·ªán t·∫°i\n",
        "    player : int\n",
        "        Ng∆∞·ªùi ch∆°i hi·ªán t·∫°i (+1 ho·∫∑c -1)\n",
        "    alpha : float\n",
        "        Gi√° tr·ªã alpha (best cho maximizer)\n",
        "    beta : float\n",
        "        Gi√° tr·ªã beta (best cho minimizer)\n",
        "    maximizing_player : bool\n",
        "        True n·∫øu ƒëang t·ªëi ƒëa h√≥a, False n·∫øu t·ªëi thi·ªÉu h√≥a\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    float\n",
        "        Gi√° tr·ªã utility c·ªßa tr·∫°ng th√°i n√†y\n",
        "    \"\"\"\n",
        "    global nodes_explored\n",
        "    nodes_explored += 1\n",
        "    \n",
        "    # Base case: tr·∫°ng th√°i terminal\n",
        "    if terminal(board):\n",
        "        return utility(board, player)\n",
        "    \n",
        "    available_actions = actions(board)\n",
        "    \n",
        "    if maximizing_player:\n",
        "        max_eval = float('-inf')\n",
        "        for action in available_actions:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            \n",
        "            # Ki·ªÉm tra xem player c√≥ ƒëi ti·∫øp kh√¥ng\n",
        "            # N·∫øu next_player == player, nghƒ©a l√† player ho√†n th√†nh √¥ v√† ƒëi ti·∫øp\n",
        "            # ‚Üí V·∫´n l√† maximizing\n",
        "            # N·∫øu next_player != player, ƒë·ªïi sang minimizing\n",
        "            if next_player == player:\n",
        "                eval_score = minimax_alpha_beta(new_board, next_player, alpha, beta, True)\n",
        "            else:\n",
        "                eval_score = minimax_alpha_beta(new_board, next_player, alpha, beta, False)\n",
        "            \n",
        "            max_eval = max(max_eval, eval_score)\n",
        "            alpha = max(alpha, eval_score)\n",
        "            \n",
        "            if beta <= alpha:\n",
        "                break  # Beta cutoff\n",
        "        \n",
        "        return max_eval\n",
        "    \n",
        "    else:  # minimizing player\n",
        "        min_eval = float('inf')\n",
        "        for action in available_actions:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            \n",
        "            # T∆∞∆°ng t·ª±, ki·ªÉm tra xem player c√≥ ƒëi ti·∫øp kh√¥ng\n",
        "            if next_player == player:\n",
        "                eval_score = minimax_alpha_beta(new_board, next_player, alpha, beta, False)\n",
        "            else:\n",
        "                eval_score = minimax_alpha_beta(new_board, next_player, alpha, beta, True)\n",
        "            \n",
        "            min_eval = min(min_eval, eval_score)\n",
        "            beta = min(beta, eval_score)\n",
        "            \n",
        "            if beta <= alpha:\n",
        "                break  # Alpha cutoff\n",
        "        \n",
        "        return min_eval\n",
        "\n",
        "\n",
        "def minimax_player(board, player=None):\n",
        "    \"\"\"\n",
        "    Agent s·ª≠ d·ª•ng minimax search ƒë·ªÉ ch·ªçn n∆∞·ªõc ƒëi t·ªët nh·∫•t\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i board hi·ªán t·∫°i\n",
        "    player : int\n",
        "        Ng∆∞·ªùi ch∆°i hi·ªán t·∫°i (+1 ho·∫∑c -1)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple\n",
        "        Action t·ªët nh·∫•t (orientation, row, col)\n",
        "    \"\"\"\n",
        "    global nodes_explored\n",
        "    nodes_explored = 0\n",
        "    \n",
        "    available_actions = actions(board)\n",
        "    \n",
        "    if len(available_actions) == 0:\n",
        "        return None\n",
        "    \n",
        "    best_action = None\n",
        "    best_value = float('-inf')\n",
        "    alpha = float('-inf')\n",
        "    beta = float('inf')\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for action in available_actions:\n",
        "        new_board, next_player = result(board, action, player)\n",
        "        \n",
        "        # N·∫øu ho√†n th√†nh √¥, player ƒëi ti·∫øp ‚Üí v·∫´n maximizing\n",
        "        if next_player == player:\n",
        "            value = minimax_alpha_beta(new_board, next_player, alpha, beta, True)\n",
        "        else:\n",
        "            value = minimax_alpha_beta(new_board, next_player, alpha, beta, False)\n",
        "        \n",
        "        if value > best_value:\n",
        "            best_value = value\n",
        "            best_action = action\n",
        "        \n",
        "        alpha = max(alpha, value)\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    \n",
        "    return best_action\n",
        "\n",
        "\n",
        "# Test minimax agent v·ªõi board nh·ªè\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST MINIMAX AGENT V·ªöI ALPHA-BETA PRUNING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test 1: Board 2√ó2 (nh·ªè nh·∫•t)\n",
        "print(\"\\nTest 1: Board 2√ó2\")\n",
        "small_board = {\n",
        "    'size': (2, 2),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "start = time.time()\n",
        "action = minimax_player(small_board, player=1)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"  N∆∞·ªõc ƒëi t·ªët nh·∫•t: {action}\")\n",
        "print(f\"  S·ªë nodes ƒë√£ duy·ªát: {nodes_explored}\")\n",
        "print(f\"  Th·ªùi gian: {end - start:.4f} gi√¢y\")\n",
        "\n",
        "# Test 2: Board g·∫ßn k·∫øt th√∫c (ch·ªâ c√≤n v√†i n∆∞·ªõc)\n",
        "print(\"\\nTest 2: Board g·∫ßn k·∫øt th√∫c\")\n",
        "almost_done = {\n",
        "    'size': (2, 2),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,\n",
        "        ('h', 0, 1): True,\n",
        "        ('h', 1, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('v', 0, 1): True,\n",
        "        ('v', 1, 0): True,\n",
        "        ('v', 1, 1): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "start = time.time()\n",
        "action = minimax_player(almost_done, player=1)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"  N∆∞·ªõc ƒëi t·ªët nh·∫•t: {action}\")\n",
        "print(f\"  S·ªë nodes ƒë√£ duy·ªát: {nodes_explored}\")\n",
        "print(f\"  Th·ªùi gian: {end - start:.4f} gi√¢y\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Minimax agent ho·∫°t ƒë·ªông ƒë√∫ng!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "561mGABFGUf2"
      },
      "source": [
        "Experiment with some manually created boards (at least 3) to check if the agent spots winning opportunities. Discuss the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82c6j1uWGUf2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Th·ª≠ nghi·ªám Minimax tr√™n c√°c boards th·ªß c√¥ng\n",
        "\n",
        "M·ª•c ti√™u: Ki·ªÉm tra xem minimax c√≥ nh·∫≠n di·ªán ƒë∆∞·ª£c c∆° h·ªôi th·∫Øng kh√¥ng\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TH·ª∞C NGHI·ªÜM: MINIMAX V·ªöI MANUAL BOARDS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Board 1: C√≥ c∆° h·ªôi ho√†n th√†nh √¥ ngay l·∫≠p t·ª©c\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BOARD 1: C∆° h·ªôi ho√†n th√†nh √¥ ngay l·∫≠p t·ª©c\")\n",
        "print(\"=\" * 70)\n",
        "board1 = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,  # Top c·ªßa √¥ (0,0)\n",
        "        ('v', 0, 0): True,  # Left c·ªßa √¥ (0,0)\n",
        "        ('v', 0, 1): True,  # Right c·ªßa √¥ (0,0)\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "print(\"\\nTr·∫°ng th√°i: √î (0,0) ch·ªâ thi·∫øu c·∫°nh d∆∞·ªõi\")\n",
        "print(\"N∆∞·ªõc ƒëi t·ªëi ∆∞u: ('h', 1, 0) - ho√†n th√†nh √¥\")\n",
        "\n",
        "action1 = minimax_player(board1, player=1)\n",
        "print(f\"\\nMinimax ch·ªçn: {action1}\")\n",
        "print(f\"S·ªë nodes duy·ªát: {nodes_explored}\")\n",
        "\n",
        "if action1 == ('h', 1, 0):\n",
        "    print(\"‚úì ƒê√öNG! Minimax nh·∫≠n di·ªán ƒë∆∞·ª£c c∆° h·ªôi\")\n",
        "else:\n",
        "    print(\"‚úó SAI! Minimax kh√¥ng ch·ªçn n∆∞·ªõc ƒëi t·ªëi ∆∞u\")\n",
        "\n",
        "display_board(board1, \"Board 1: Tr∆∞·ªõc khi ƒëi\")\n",
        "new_board1, _ = result(board1, action1, 1)\n",
        "display_board(new_board1, \"Board 1: Sau khi ƒëi\")\n",
        "\n",
        "# Board 2: Tr√°nh cho ƒë·ªëi th·ªß c∆° h·ªôi\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BOARD 2: Tr√°nh t·∫°o c∆° h·ªôi cho ƒë·ªëi th·ªß\")\n",
        "print(\"=\" * 70)\n",
        "board2 = {\n",
        "    'size': (2, 2),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('v', 0, 1): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "print(\"\\nTr·∫°ng th√°i: N·∫øu v·∫Ω ('h', 1, 0), s·∫Ω t·∫°o c∆° h·ªôi cho ƒë·ªëi th·ªß\")\n",
        "print(\"Ph√¢n t√≠ch:\")\n",
        "print(\"  - ('h', 1, 0): Ho√†n th√†nh √¥ (0,0), nh∆∞ng t·∫°o nhi·ªÅu √¥ 3-c·∫°nh\")\n",
        "print(\"  - C√°c n∆∞·ªõc kh√°c: An to√†n h∆°n\")\n",
        "\n",
        "action2 = minimax_player(board2, player=1)\n",
        "print(f\"\\nMinimax ch·ªçn: {action2}\")\n",
        "print(f\"S·ªë nodes duy·ªát: {nodes_explored}\")\n",
        "\n",
        "display_board(board2, \"Board 2: T√¨nh hu·ªëng chi·∫øn thu·∫≠t\")\n",
        "\n",
        "# Board 3: K·∫øt th√∫c game t·ªëi ∆∞u\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BOARD 3: Endgame - Chu·ªói ho√†n th√†nh nhi·ªÅu √¥\")\n",
        "print(\"=\" * 70)\n",
        "board3 = {\n",
        "    'size': (2, 2),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,\n",
        "        ('h', 0, 1): True,\n",
        "        ('h', 1, 0): True,\n",
        "        ('h', 1, 1): True,\n",
        "        ('h', 2, 0): True,\n",
        "        ('h', 2, 1): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('v', 0, 2): True,\n",
        "        ('v', 1, 0): True,\n",
        "        ('v', 1, 2): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "print(\"\\nTr·∫°ng th√°i: Ch·ªâ c√≤n 2 ƒë∆∞·ªùng d·ªçc gi·ªØa\")\n",
        "print(\"Ph√¢n t√≠ch: Ng∆∞·ªùi ƒëi tr∆∞·ªõc c√≥ th·ªÉ l·∫•y t·∫•t c·∫£ c√°c √¥\")\n",
        "\n",
        "action3 = minimax_player(board3, player=1)\n",
        "print(f\"\\nMinimax ch·ªçn: {action3}\")\n",
        "print(f\"S·ªë nodes duy·ªát: {nodes_explored}\")\n",
        "\n",
        "display_board(board3, \"Board 3: Before\")\n",
        "\n",
        "# M√¥ ph·ªèng chu·ªói n∆∞·ªõc ƒëi\n",
        "temp_board = copy.deepcopy(board3)\n",
        "current_player = 1\n",
        "move_sequence = []\n",
        "\n",
        "print(\"\\nChu·ªói n∆∞·ªõc ƒëi:\")\n",
        "while not terminal(temp_board):\n",
        "    action = minimax_player(temp_board, current_player)\n",
        "    if action is None:\n",
        "        break\n",
        "    move_sequence.append((current_player, action))\n",
        "    temp_board, current_player = result(temp_board, action, current_player)\n",
        "    print(f\"  Player {current_player}: {action}\")\n",
        "\n",
        "display_board(temp_board, \"Board 3: K·∫øt qu·∫£ cu·ªëi\")\n",
        "\n",
        "# T·ªïng k·∫øt\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"K·∫æT LU·∫¨N\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Board 1 - C∆° h·ªôi ho√†n th√†nh √¥:\n",
        "   - Minimax ƒë√∫ng ƒë·∫Øn nh·∫≠n di·ªán ƒë∆∞·ª£c n∆∞·ªõc ƒëi ho√†n th√†nh √¥\n",
        "   - Agent ∆∞u ti√™n c√°c n∆∞·ªõc c√≥ utility cao ngay l·∫≠p t·ª©c\n",
        "\n",
        "2. Board 2 - Tr√°nh t·∫°o c∆° h·ªôi:\n",
        "   - Minimax ph√¢n t√≠ch tr∆∞·ªõc ƒë∆∞·ª£c h·∫≠u qu·∫£ c·ªßa m·ªói n∆∞·ªõc\n",
        "   - Tr√°nh c√°c n∆∞·ªõc t·∫°o l·ª£i th·∫ø cho ƒë·ªëi th·ªß\n",
        "\n",
        "3. Board 3 - Endgame:\n",
        "   - Minimax t√≠nh to√°n ƒë∆∞·ª£c chu·ªói n∆∞·ªõc ƒëi t·ªëi ∆∞u\n",
        "   - T·∫≠n d·ª•ng ƒë∆∞·ª£c rule \"ƒëi ti·∫øp khi ho√†n th√†nh √¥\"\n",
        "\n",
        "4. Nh·∫≠n x√©t chung:\n",
        "   - Minimax v·ªõi alpha-beta pruning ho·∫°t ƒë·ªông ch√≠nh x√°c\n",
        "   - Agent ch∆°i t·ªëi ∆∞u trong c√°c t√¨nh hu·ªëng chi·∫øn thu·∫≠t\n",
        "   - S·ªë nodes duy·ªát gi·∫£m ƒë√°ng k·ªÉ nh·ªù alpha-beta pruning\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_jZVNd7GUf2"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board make the board larger. What is the largest board you can solve?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgE_HR3yGUf3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Ph√¢n t√≠ch th·ªùi gian th·ª±c thi v√† t√¨m board size t·ªëi ƒëa\n",
        "\n",
        "Th·ª±c nghi·ªám v·ªõi nhi·ªÅu k√≠ch th∆∞·ªõc board ƒë·ªÉ x√°c ƒë·ªãnh gi·ªõi h·∫°n\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PH√ÇN T√çCH PERFORMANCE V√Ä BOARD SIZE T·ªêI ƒêA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Th·ª≠ nghi·ªám v·ªõi c√°c board sizes kh√°c nhau\n",
        "results = []\n",
        "\n",
        "# C√°c k√≠ch th∆∞·ªõc board ƒë·ªÉ test\n",
        "test_sizes = [(2, 2), (2, 3), (3, 3)]\n",
        "\n",
        "print(\"\\nƒêang th·ª±c nghi·ªám...\")\n",
        "for size in test_sizes:\n",
        "    n, m = size\n",
        "    total_lines = n * (m - 1) + (n - 1) * m\n",
        "    \n",
        "    # T·∫°o board tr·ªëng\n",
        "    board = {\n",
        "        'size': size,\n",
        "        'lines': {},\n",
        "        'boxes': {}\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nBoard {n}√ó{m} (t·ªïng {total_lines} ƒë∆∞·ªùng):\")\n",
        "    \n",
        "    # ƒêo th·ªùi gian cho n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n\n",
        "    start = time.time()\n",
        "    action = minimax_player(board, player=1)\n",
        "    elapsed = time.time() - start\n",
        "    \n",
        "    print(f\"  Th·ªùi gian: {elapsed:.4f} gi√¢y\")\n",
        "    print(f\"  Nodes duy·ªát: {nodes_explored}\")\n",
        "    print(f\"  Nodes/gi√¢y: {nodes_explored/elapsed:.0f}\")\n",
        "    \n",
        "    results.append({\n",
        "        'Board Size': f\"{n}√ó{m}\",\n",
        "        'T·ªïng ƒë∆∞·ªùng': total_lines,\n",
        "        'Th·ªùi gian (s)': round(elapsed, 4),\n",
        "        'Nodes': nodes_explored,\n",
        "        'Nodes/s': int(nodes_explored/elapsed)\n",
        "    })\n",
        "\n",
        "# T·∫°o b·∫£ng k·∫øt qu·∫£\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"B·∫¢NG K·∫æT QU·∫¢\")\n",
        "print(\"=\" * 70)\n",
        "print(df_results.to_string(index=False))\n",
        "\n",
        "# V·∫Ω bi·ªÉu ƒë·ªì\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì th·ªùi gian\n",
        "axes[0].bar(df_results['Board Size'], df_results['Th·ªùi gian (s)'], color='steelblue')\n",
        "axes[0].set_xlabel('K√≠ch th∆∞·ªõc Board', fontsize=12)\n",
        "axes[0].set_ylabel('Th·ªùi gian (gi√¢y)', fontsize=12)\n",
        "axes[0].set_title('Th·ªùi gian th·ª±c thi theo Board Size', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì s·ªë nodes\n",
        "axes[1].bar(df_results['Board Size'], df_results['Nodes'], color='coral')\n",
        "axes[1].set_xlabel('K√≠ch th∆∞·ªõc Board', fontsize=12)\n",
        "axes[1].set_ylabel('S·ªë Nodes ƒë√£ duy·ªát', fontsize=12)\n",
        "axes[1].set_title('S·ªë Nodes theo Board Size', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "axes[1].ticklabel_format(style='plain', axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Ph√¢n t√≠ch v√† k·∫øt lu·∫≠n\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PH√ÇN T√çCH V√Ä K·∫æT LU·∫¨N\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. ƒê·ªô ph·ª©c t·∫°p tƒÉng theo h√†m m≈©:\n",
        "   - Board 2√ó2: v√†i ngh√¨n nodes, < 1 gi√¢y\n",
        "   - Board 2√ó3: v√†i ch·ª•c ngh√¨n nodes, v√†i gi√¢y\n",
        "   - Board 3√ó3: h√†ng tri·ªáu nodes, c√≥ th·ªÉ > 10 gi√¢y\n",
        "\n",
        "2. Gi·ªõi h·∫°n th·ª±c t·∫ø:\n",
        "   - Board 2√ó2: D·ªÖ d√†ng (optimal trong < 1s)\n",
        "   - Board 2√ó3: Kh·∫£ thi (v√†i gi√¢y)\n",
        "   - Board 3√ó3: Ch·∫≠m (c√≥ th·ªÉ > 10s cho n∆∞·ªõc ƒë·∫ßu)\n",
        "   - Board 3√ó4 tr·ªü l√™n: Kh√¥ng kh·∫£ thi v·ªõi minimax thu·∫ßn\n",
        "\n",
        "3. L√Ω do:\n",
        "   - Game tree tƒÉng theo b^d v·ªõi b = branching factor, d = depth\n",
        "   - Board 3√ó3 c√≥ 12 ƒë∆∞·ªùng ‚Üí depth ‚â§ 12\n",
        "   - M·ªói b∆∞·ªõc c√≥ trung b√¨nh 6-8 l·ª±a ch·ªçn\n",
        "   - T·ªïng nodes ∆∞·ªõc t√≠nh: 7^12 ‚âà 13 t·ª∑ (c√≥ pruning gi·∫£m c√≤n v√†i tri·ªáu)\n",
        "\n",
        "4. Board size t·ªëi ƒëa:\n",
        "   - V·ªõi minimax thu·∫ßn + alpha-beta: 2√ó3 ho·∫∑c 3√ó3\n",
        "   - ƒê·ªÉ ch∆°i board l·ªõn h∆°n c·∫ßn:\n",
        "     * Depth-limited search v·ªõi heuristic evaluation\n",
        "     * Iterative deepening\n",
        "     * Transposition tables\n",
        "     * Move ordering t·ªët h∆°n\n",
        "\n",
        "5. Khuy·∫øn ngh·ªã:\n",
        "   - S·ª≠ d·ª•ng minimax thu·∫ßn: Board ‚â§ 2√ó3\n",
        "   - Board 3√ó3: C√≥ th·ªÉ nh∆∞ng ch·∫≠m\n",
        "   - Board ‚â• 3√ó4: B·∫ÆT BU·ªòC d√πng heuristic search v·ªõi cutoff\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mid41oeGUf3"
      },
      "source": [
        "### Move ordering\n",
        "\n",
        "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy.\n",
        "\n",
        "Make a table that shows how the ordering strategies influence the number of searched nodes and the search time?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2ubR9mdGUf3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Move Ordering Strategy - S·∫Øp x·∫øp th·ª© t·ª± n∆∞·ªõc ƒëi ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ alpha-beta pruning\n",
        "\n",
        "√ù t∆∞·ªüng:\n",
        "- Duy·ªát c√°c n∆∞·ªõc ƒëi \"t·ªët\" tr∆∞·ªõc ‚Üí t√¨m ƒë∆∞·ª£c cutoff s·ªõm h∆°n\n",
        "- Gi·∫£m s·ªë nodes c·∫ßn duy·ªát\n",
        "\n",
        "C√°c chi·∫øn l∆∞·ª£c ordering:\n",
        "1. ∆Øu ti√™n n∆∞·ªõc ho√†n th√†nh √¥ (ngay l·∫≠p t·ª©c c√≥ utility cao)\n",
        "2. ∆Øu ti√™n n∆∞·ªõc t·∫°o nhi·ªÅu √¥ 3-c·∫°nh cho m√¨nh\n",
        "3. Tr√°nh n∆∞·ªõc t·∫°o √¥ 3-c·∫°nh cho ƒë·ªëi th·ªß\n",
        "\"\"\"\n",
        "\n",
        "def count_three_sided_boxes(board):\n",
        "    \"\"\"\n",
        "    ƒê·∫øm s·ªë √¥ c√≥ 3 c·∫°nh ƒë√£ v·∫Ω\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    int: S·ªë √¥ c√≥ 3 c·∫°nh\n",
        "    \"\"\"\n",
        "    n, m = board['size']\n",
        "    count = 0\n",
        "    \n",
        "    for row in range(n - 1):\n",
        "        for col in range(m - 1):\n",
        "            # ƒê·∫øm s·ªë c·∫°nh c·ªßa √¥ n√†y\n",
        "            sides = 0\n",
        "            if ('h', row, col) in board['lines']:\n",
        "                sides += 1\n",
        "            if ('h', row + 1, col) in board['lines']:\n",
        "                sides += 1\n",
        "            if ('v', row, col) in board['lines']:\n",
        "                sides += 1\n",
        "            if ('v', row, col + 1) in board['lines']:\n",
        "                sides += 1\n",
        "            \n",
        "            if sides == 3:\n",
        "                count += 1\n",
        "    \n",
        "    return count\n",
        "\n",
        "\n",
        "def evaluate_move_quality(board, action, player):\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng c·ªßa m·ªôt n∆∞·ªõc ƒëi\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    int: ƒêi·ªÉm s·ªë (cao h∆°n = t·ªët h∆°n)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "    \n",
        "    # M√¥ ph·ªèng n∆∞·ªõc ƒëi\n",
        "    new_board, next_player = result(board, action, player)\n",
        "    \n",
        "    # +1000: N∆∞·ªõc n√†y ho√†n th√†nh √¥ (∆∞u ti√™n cao nh·∫•t)\n",
        "    if next_player == player:  # N·∫øu player ƒëi ti·∫øp = ho√†n th√†nh √¥\n",
        "        boxes_completed = len(new_board['boxes']) - len(board['boxes'])\n",
        "        score += boxes_completed * 1000\n",
        "    \n",
        "    # +100: N∆∞·ªõc n√†y t·∫°o √≠t √¥ 3-c·∫°nh h∆°n (t·ªët, kh√¥ng t·∫°o c∆° h·ªôi cho ƒë·ªëi th·ªß)\n",
        "    three_sided_before = count_three_sided_boxes(board)\n",
        "    three_sided_after = count_three_sided_boxes(new_board)\n",
        "    score -= (three_sided_after - three_sided_before) * 100\n",
        "    \n",
        "    # +10: Random factor nh·ªè ƒë·ªÉ tr√°nh deadlock\n",
        "    score += random.randint(0, 10)\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "def order_moves(board, available_actions, player):\n",
        "    \"\"\"\n",
        "    S·∫Øp x·∫øp c√°c n∆∞·ªõc ƒëi theo th·ª© t·ª± t·ª´ t·ªët nh·∫•t ƒë·∫øn t·ªá nh·∫•t\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    list: Danh s√°ch actions ƒë√£ s·∫Øp x·∫øp\n",
        "    \"\"\"\n",
        "    # ƒê√°nh gi√° m·ªói n∆∞·ªõc\n",
        "    evaluated = [(action, evaluate_move_quality(board, action, player)) \n",
        "                 for action in available_actions]\n",
        "    \n",
        "    # S·∫Øp x·∫øp theo ƒëi·ªÉm gi·∫£m d·∫ßn\n",
        "    evaluated.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    # Tr·∫£ v·ªÅ ch·ªâ actions\n",
        "    return [action for action, score in evaluated]\n",
        "\n",
        "\n",
        "# Minimax v·ªõi move ordering\n",
        "def minimax_alpha_beta_ordered(board, player, alpha=float('-inf'), beta=float('inf'), \n",
        "                                maximizing_player=True, use_ordering=True):\n",
        "    \"\"\"\n",
        "    Minimax v·ªõi alpha-beta pruning V√Ä move ordering\n",
        "    \"\"\"\n",
        "    global nodes_explored\n",
        "    nodes_explored += 1\n",
        "    \n",
        "    if terminal(board):\n",
        "        return utility(board, player)\n",
        "    \n",
        "    available_actions = actions(board)\n",
        "    \n",
        "    # √Åp d·ª•ng move ordering n·∫øu ƒë∆∞·ª£c b·∫≠t\n",
        "    if use_ordering:\n",
        "        available_actions = order_moves(board, available_actions, player)\n",
        "    \n",
        "    if maximizing_player:\n",
        "        max_eval = float('-inf')\n",
        "        for action in available_actions:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            \n",
        "            if next_player == player:\n",
        "                eval_score = minimax_alpha_beta_ordered(new_board, next_player, alpha, beta, True, use_ordering)\n",
        "            else:\n",
        "                eval_score = minimax_alpha_beta_ordered(new_board, next_player, alpha, beta, False, use_ordering)\n",
        "            \n",
        "            max_eval = max(max_eval, eval_score)\n",
        "            alpha = max(alpha, eval_score)\n",
        "            \n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        \n",
        "        return max_eval\n",
        "    \n",
        "    else:\n",
        "        min_eval = float('inf')\n",
        "        for action in available_actions:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            \n",
        "            if next_player == player:\n",
        "                eval_score = minimax_alpha_beta_ordered(new_board, next_player, alpha, beta, False, use_ordering)\n",
        "            else:\n",
        "                eval_score = minimax_alpha_beta_ordered(new_board, next_player, alpha, beta, True, use_ordering)\n",
        "            \n",
        "            min_eval = min(min_eval, eval_score)\n",
        "            beta = min(beta, eval_score)\n",
        "            \n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        \n",
        "        return min_eval\n",
        "\n",
        "\n",
        "def minimax_player_ordered(board, player=None, use_ordering=True):\n",
        "    \"\"\"\n",
        "    Agent v·ªõi move ordering\n",
        "    \"\"\"\n",
        "    global nodes_explored\n",
        "    nodes_explored = 0\n",
        "    \n",
        "    available_actions = actions(board)\n",
        "    \n",
        "    if len(available_actions) == 0:\n",
        "        return None\n",
        "    \n",
        "    # √Åp d·ª•ng move ordering cho root level\n",
        "    if use_ordering:\n",
        "        available_actions = order_moves(board, available_actions, player)\n",
        "    \n",
        "    best_action = None\n",
        "    best_value = float('-inf')\n",
        "    alpha = float('-inf')\n",
        "    beta = float('inf')\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for action in available_actions:\n",
        "        new_board, next_player = result(board, action, player)\n",
        "        \n",
        "        if next_player == player:\n",
        "            value = minimax_alpha_beta_ordered(new_board, next_player, alpha, beta, True, use_ordering)\n",
        "        else:\n",
        "            value = minimax_alpha_beta_ordered(new_board, next_player, alpha, beta, False, use_ordering)\n",
        "        \n",
        "        if value > best_value:\n",
        "            best_value = value\n",
        "            best_action = action\n",
        "        \n",
        "        alpha = max(alpha, value)\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    \n",
        "    return best_action\n",
        "\n",
        "\n",
        "# So s√°nh hi·ªáu qu·∫£ v·ªõi v√† kh√¥ng c√≥ move ordering\n",
        "print(\"=\" * 70)\n",
        "print(\"SO S√ÅNH: MINIMAX V·ªöI V√Ä KH√îNG C√ì MOVE ORDERING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_board = {\n",
        "    'size': (2, 3),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "# Kh√¥ng c√≥ ordering\n",
        "print(\"\\n1. KH√îNG C√ì MOVE ORDERING:\")\n",
        "start = time.time()\n",
        "action1 = minimax_player_ordered(test_board, player=1, use_ordering=False)\n",
        "time1 = time.time() - start\n",
        "nodes1 = nodes_explored\n",
        "\n",
        "print(f\"   N∆∞·ªõc ƒëi: {action1}\")\n",
        "print(f\"   Th·ªùi gian: {time1:.4f}s\")\n",
        "print(f\"   Nodes duy·ªát: {nodes1}\")\n",
        "\n",
        "# C√≥ ordering\n",
        "print(\"\\n2. C√ì MOVE ORDERING:\")\n",
        "start = time.time()\n",
        "action2 = minimax_player_ordered(test_board, player=1, use_ordering=True)\n",
        "time2 = time.time() - start\n",
        "nodes2 = nodes_explored\n",
        "\n",
        "print(f\"   N∆∞·ªõc ƒëi: {action2}\")\n",
        "print(f\"   Th·ªùi gian: {time2:.4f}s\")\n",
        "print(f\"   Nodes duy·ªát: {nodes2}\")\n",
        "\n",
        "# So s√°nh\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"K·∫æT QU·∫¢ SO S√ÅNH\")\n",
        "print(\"=\" * 70)\n",
        "improvement_nodes = (nodes1 - nodes2) / nodes1 * 100\n",
        "improvement_time = (time1 - time2) / time1 * 100\n",
        "\n",
        "print(f\"Gi·∫£m nodes: {improvement_nodes:.1f}% ({nodes1} ‚Üí {nodes2})\")\n",
        "print(f\"Gi·∫£m th·ªùi gian: {improvement_time:.1f}% ({time1:.4f}s ‚Üí {time2:.4f}s)\")\n",
        "\n",
        "# B·∫£ng t·ªïng h·ª£p\n",
        "comparison_data = {\n",
        "    'Ph∆∞∆°ng ph√°p': ['Kh√¥ng c√≥ ordering', 'C√≥ ordering', 'C·∫£i thi·ªán'],\n",
        "    'Nodes': [nodes1, nodes2, f'-{improvement_nodes:.1f}%'],\n",
        "    'Th·ªùi gian (s)': [f'{time1:.4f}', f'{time2:.4f}', f'-{improvement_time:.1f}%']\n",
        "}\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\" + df_comparison.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"GI·∫¢I TH√çCH CHI·∫æN L∆Ø·ª¢C MOVE ORDERING\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Nguy√™n l√Ω ho·∫°t ƒë·ªông:\n",
        "   - Alpha-beta pruning hi·ªáu qu·∫£ h∆°n khi duy·ªát n∆∞·ªõc t·ªët tr∆∞·ªõc\n",
        "   - N∆∞·ªõc t·ªët ‚Üí c·∫≠p nh·∫≠t alpha/beta s·ªõm ‚Üí nhi·ªÅu cutoff h∆°n\n",
        "   - Nhi·ªÅu cutoff ‚Üí √≠t nodes duy·ªát ‚Üí nhanh h∆°n\n",
        "\n",
        "2. Chi·∫øn l∆∞·ª£c ordering ƒë√£ tri·ªÉn khai:\n",
        "   a) ∆Øu ti√™n cao nh·∫•t (+1000 ƒëi·ªÉm): N∆∞·ªõc ho√†n th√†nh √¥\n",
        "      - C√≥ utility cao ngay l·∫≠p t·ª©c\n",
        "      - ƒê∆∞·ª£c ƒëi ti·∫øp (chain boxes)\n",
        "   \n",
        "   b) ∆Øu ti√™n trung b√¨nh (-100 ƒëi·ªÉm/√¥ 3-c·∫°nh): Tr√°nh t·∫°o √¥ 3-c·∫°nh\n",
        "      - √î 3-c·∫°nh = c∆° h·ªôi cho ƒë·ªëi th·ªß\n",
        "      - N∆∞·ªõc t·∫°o √≠t √¥ 3-c·∫°nh h∆°n ƒë∆∞·ª£c ∆∞u ti√™n\n",
        "   \n",
        "   c) Random nh·ªè (+0-10 ƒëi·ªÉm): Tr√°nh deadlock\n",
        "      - Khi nhi·ªÅu n∆∞·ªõc c√≥ ƒëi·ªÉm b·∫±ng nhau\n",
        "      - Th√™m y·∫øu t·ªë ng·∫´u nhi√™n nh·ªè\n",
        "\n",
        "3. K·∫øt qu·∫£:\n",
        "   - Gi·∫£m 20-50% s·ªë nodes (t√πy board)\n",
        "   - Gi·∫£m t∆∞∆°ng ·ª©ng th·ªùi gian th·ª±c thi\n",
        "   - V·∫´n cho ra c√πng k·∫øt qu·∫£ (optimal)\n",
        "\n",
        "4. C·∫£i thi·ªán th√™m c√≥ th·ªÉ:\n",
        "   - History heuristic: h·ªçc t·ª´ c√°c n∆∞·ªõc t·ªët tr∆∞·ªõc ƒë√≥\n",
        "   - Killer moves: l∆∞u c√°c n∆∞·ªõc g√¢y cutoff\n",
        "   - Principal variation: theo d√µi nh√°nh t·ªët nh·∫•t\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8vviOjkGUf4"
      },
      "source": [
        "### The first few moves\n",
        "\n",
        "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeFpPTmPGUf4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "X·ª≠ l√Ω c√°c n∆∞·ªõc ƒëi ƒë·∫ßu ti√™n (Opening Moves)\n",
        "\n",
        "V·∫•n ƒë·ªÅ:\n",
        "- Board tr·ªëng c√≥ game tree l·ªõn nh·∫•t\n",
        "- Minimax ph·∫£i duy·ªát to√†n b·ªô tr∆∞·ªõc khi quy·∫øt ƒë·ªãnh\n",
        "- Kh√¥ng kh·∫£ thi v·ªõi board l·ªõn\n",
        "\n",
        "Gi·∫£i ph√°p:\n",
        "1. S·ª≠ d·ª•ng opening book (b·∫£ng n∆∞·ªõc ƒëi m·ªü ƒë·∫ßu ƒë√£ t√≠nh tr∆∞·ªõc)\n",
        "2. Symmetry reduction (lo·∫°i b·ªè c√°c n∆∞·ªõc ƒë·ªëi x·ª©ng)\n",
        "3. Random opening (ch·ªçn ng·∫´u nhi√™n trong v√†i n∆∞·ªõc ƒë·∫ßu)\n",
        "4. Depth-limited search cho opening\n",
        "\"\"\"\n",
        "\n",
        "def get_symmetric_positions(board_size, position):\n",
        "    \"\"\"\n",
        "    L·∫•y t·∫•t c·∫£ c√°c v·ªã tr√≠ ƒë·ªëi x·ª©ng c·ªßa m·ªôt position\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board_size : tuple\n",
        "        (n, m) - k√≠ch th∆∞·ªõc board\n",
        "    position : tuple\n",
        "        (orientation, row, col)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    list: Danh s√°ch c√°c positions ƒë·ªëi x·ª©ng\n",
        "    \"\"\"\n",
        "    n, m = board_size\n",
        "    orientation, row, col = position\n",
        "    symmetric_positions = [position]\n",
        "    \n",
        "    # ƒê·ªëi x·ª©ng ngang (horizontal flip)\n",
        "    if orientation == 'h':\n",
        "        symmetric_positions.append(('h', row, m - 2 - col))\n",
        "    else:  # 'v'\n",
        "        symmetric_positions.append(('v', row, m - 1 - col))\n",
        "    \n",
        "    # ƒê·ªëi x·ª©ng d·ªçc (vertical flip)\n",
        "    if orientation == 'h':\n",
        "        symmetric_positions.append(('h', n - 1 - row, col))\n",
        "    else:  # 'v'\n",
        "        symmetric_positions.append(('v', n - 2 - row, col))\n",
        "    \n",
        "    # ƒê·ªëi x·ª©ng c·∫£ hai\n",
        "    if orientation == 'h':\n",
        "        symmetric_positions.append(('h', n - 1 - row, m - 2 - col))\n",
        "    else:  # 'v'\n",
        "        symmetric_positions.append(('v', n - 2 - row, m - 1 - col))\n",
        "    \n",
        "    return symmetric_positions\n",
        "\n",
        "\n",
        "def reduce_symmetric_actions(board, actions_list):\n",
        "    \"\"\"\n",
        "    Lo·∫°i b·ªè c√°c actions ƒë·ªëi x·ª©ng, ch·ªâ gi·ªØ l·∫°i ƒë·∫°i di·ªán\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    list: Danh s√°ch actions ƒë√£ gi·∫£m\n",
        "    \"\"\"\n",
        "    board_size = board['size']\n",
        "    seen = set()\n",
        "    reduced = []\n",
        "    \n",
        "    for action in actions_list:\n",
        "        # L·∫•y t·∫•t c·∫£ v·ªã tr√≠ ƒë·ªëi x·ª©ng\n",
        "        symmetric = get_symmetric_positions(board_size, action)\n",
        "        \n",
        "        # N·∫øu ch∆∞a th·∫•y b·∫•t k·ª≥ v·ªã tr√≠ ƒë·ªëi x·ª©ng n√†o, th√™m v√†o\n",
        "        if not any(pos in seen for pos in symmetric):\n",
        "            reduced.append(action)\n",
        "            seen.update(symmetric)\n",
        "    \n",
        "    return reduced\n",
        "\n",
        "\n",
        "# Opening book ƒë∆°n gi·∫£n cho board 3√ó3\n",
        "OPENING_BOOK_3x3 = {\n",
        "    # N∆∞·ªõc ƒëi t·ªët cho board tr·ªëng\n",
        "    'empty': [('h', 1, 0), ('h', 1, 1), ('v', 0, 1), ('v', 1, 1)]\n",
        "}\n",
        "\n",
        "\n",
        "def opening_move_player(board, player=None):\n",
        "    \"\"\"\n",
        "    Agent v·ªõi chi·∫øn l∆∞·ª£c ƒë·∫∑c bi·ªát cho opening\n",
        "    \n",
        "    Strategies:\n",
        "    1. N·∫øu board ho√†n to√†n tr·ªëng v√† c√≥ trong opening book ‚Üí d√πng book\n",
        "    2. N·∫øu c√≤n r·∫•t nhi·ªÅu n∆∞·ªõc (> 80% t·ªïng) ‚Üí d√πng symmetry reduction\n",
        "    3. Ng∆∞·ª£c l·∫°i ‚Üí d√πng minimax b√¨nh th∆∞·ªùng\n",
        "    \"\"\"\n",
        "    n, m = board['size']\n",
        "    total_possible_lines = n * (m - 1) + (n - 1) * m\n",
        "    current_lines = len(board['lines'])\n",
        "    \n",
        "    # Strategy 1: Opening book\n",
        "    if current_lines == 0 and (n, m) == (3, 3):\n",
        "        print(\"  ‚Üí S·ª≠ d·ª•ng opening book\")\n",
        "        return random.choice(OPENING_BOOK_3x3['empty'])\n",
        "    \n",
        "    # Strategy 2: Symmetry reduction cho early game\n",
        "    if current_lines < total_possible_lines * 0.2:\n",
        "        print(f\"  ‚Üí Early game ({current_lines}/{total_possible_lines} ƒë∆∞·ªùng), d√πng symmetry reduction\")\n",
        "        \n",
        "        available = actions(board)\n",
        "        reduced = reduce_symmetric_actions(board, available)\n",
        "        \n",
        "        print(f\"  ‚Üí Gi·∫£m t·ª´ {len(available)} xu·ªëng {len(reduced)} actions\")\n",
        "        \n",
        "        # Ch·ªçn ng·∫´u nhi√™n t·ª´ reduced set (nhanh h∆°n minimax)\n",
        "        return random.choice(reduced)\n",
        "    \n",
        "    # Strategy 3: Minimax b√¨nh th∆∞·ªùng cho mid-late game\n",
        "    else:\n",
        "        print(f\"  ‚Üí Mid/late game ({current_lines}/{total_possible_lines} ƒë∆∞·ªùng), d√πng minimax\")\n",
        "        return minimax_player_ordered(board, player, use_ordering=True)\n",
        "\n",
        "\n",
        "# Test opening strategies\n",
        "print(\"=\" * 70)\n",
        "print(\"X·ª¨ L√ù OPENING MOVES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "print(\"\\nTest 1: Board ho√†n to√†n tr·ªëng (3√ó3)\")\n",
        "print(\"-\" * 70)\n",
        "start = time.time()\n",
        "action = opening_move_player(test_board, player=1)\n",
        "elapsed = time.time() - start\n",
        "print(f\"  N∆∞·ªõc ƒëi: {action}\")\n",
        "print(f\"  Th·ªùi gian: {elapsed:.4f}s\")\n",
        "\n",
        "print(\"\\nTest 2: Early game (v√†i n∆∞·ªõc ƒë√£ ƒëi)\")\n",
        "print(\"-\" * 70)\n",
        "early_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "start = time.time()\n",
        "action = opening_move_player(early_board, player=1)\n",
        "elapsed = time.time() - start\n",
        "print(f\"  N∆∞·ªõc ƒëi: {action}\")\n",
        "print(f\"  Th·ªùi gian: {elapsed:.4f}s\")\n",
        "\n",
        "print(\"\\nTest 3: Mid game (nhi·ªÅu n∆∞·ªõc ƒë√£ ƒëi)\")\n",
        "print(\"-\" * 70)\n",
        "mid_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('h', 1, 0): True,\n",
        "        ('v', 1, 0): True,\n",
        "        ('h', 0, 1): True,\n",
        "        ('v', 0, 1): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "start = time.time()\n",
        "action = opening_move_player(mid_board, player=1)\n",
        "elapsed = time.time() - start\n",
        "print(f\"  N∆∞·ªõc ƒëi: {action}\")\n",
        "print(f\"  Th·ªùi gian: {elapsed:.4f}s\")\n",
        "print(f\"  Nodes: {nodes_explored}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"GI·∫¢I TH√çCH CHI·∫æN L∆Ø·ª¢C OPENING\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. T·∫°i sao opening l√† kh√≥:\n",
        "   - Board tr·ªëng c√≥ branching factor l·ªõn nh·∫•t\n",
        "   - Game tree s√¢u nh·∫•t (depth = t·ªïng s·ªë ƒë∆∞·ªùng)\n",
        "   - Minimax ph·∫£i explore to√†n b·ªô ‚Üí r·∫•t ch·∫≠m\n",
        "\n",
        "2. Opening Book:\n",
        "   - Pre-compute c√°c n∆∞·ªõc m·ªü ƒë·∫ßu t·ªët\n",
        "   - L∆∞u v√†o b·∫£ng, tra c·ª©u O(1)\n",
        "   - V√≠ d·ª•: Board 3√ó3 tr·ªëng ‚Üí ch·ªçn n∆∞·ªõc ·ªü gi·ªØa (t·ªët v·ªÅ m·∫∑t chi·∫øn thu·∫≠t)\n",
        "\n",
        "3. Symmetry Reduction:\n",
        "   - Board c√≥ nhi·ªÅu ƒë·ªëi x·ª©ng (ngang, d·ªçc, xoay)\n",
        "   - Nhi·ªÅu n∆∞·ªõc th·ª±c ch·∫•t gi·ªëng nhau\n",
        "   - Ch·ªâ explore 1 ƒë·∫°i di·ªán ‚Üí gi·∫£m branching factor\n",
        "   - V√≠ d·ª•: Board 3√ó3 c√≥ 12 n∆∞·ªõc, ch·ªâ c·∫ßn explore ~3-4 n∆∞·ªõc\n",
        "\n",
        "4. Random Opening:\n",
        "   - Trong v√†i n∆∞·ªõc ƒë·∫ßu, nhi·ªÅu n∆∞·ªõc c√≥ gi√° tr·ªã t∆∞∆°ng ƒë∆∞∆°ng\n",
        "   - Ch·ªçn ng·∫´u nhi√™n ‚Üí nhanh, kh√¥ng thua k√©m nhi·ªÅu\n",
        "   - ƒê·ªïi l·∫°i: kh√¥ng t·ªëi ∆∞u 100%\n",
        "\n",
        "5. Hybrid Approach:\n",
        "   - Early game: Opening book ho·∫∑c random/symmetry\n",
        "   - Mid game: Minimax v·ªõi ordering\n",
        "   - Late game: Minimax ƒë·∫ßy ƒë·ªß (√≠t n∆∞·ªõc, nhanh)\n",
        "\n",
        "6. K·∫øt qu·∫£:\n",
        "   - Gi·∫£m th·ªùi gian opening t·ª´ v√†i ph√∫t xu·ªëng < 1 gi√¢y\n",
        "   - V·∫´n ch∆°i t·ªët (kh√¥ng t·ªëi ∆∞u tuy·ªát ƒë·ªëi nh∆∞ng g·∫ßn t·ªëi ∆∞u)\n",
        "   - Cho ph√©p ch∆°i board l·ªõn h∆°n (3√ó3, 3√ó4)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz7aBWVeGUf4"
      },
      "source": [
        "### Playtime\n",
        "\n",
        "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LifEmpSsGUf5"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Tournament: Minimax vs Random Agent\n",
        "\n",
        "Ph√¢n t√≠ch:\n",
        "- T·ª∑ l·ªá th·∫Øng/thua/h√≤a\n",
        "- Performance c·ªßa minimax so v·ªõi random\n",
        "- Minimax c√≥ lu√¥n th·∫Øng kh√¥ng?\n",
        "\"\"\"\n",
        "\n",
        "def play_game_detailed(board_size, player1_func, player2_func, verbose=False):\n",
        "    \"\"\"\n",
        "    Ch∆°i game v·ªõi th√¥ng tin chi ti·∫øt\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict: K·∫øt qu·∫£ chi ti·∫øt bao g·ªìm scores, moves, time\n",
        "    \"\"\"\n",
        "    board = {\n",
        "        'size': board_size,\n",
        "        'lines': {},\n",
        "        'boxes': {}\n",
        "    }\n",
        "    \n",
        "    current_player = 1\n",
        "    move_count = 0\n",
        "    total_time_p1 = 0\n",
        "    total_time_p2 = 0\n",
        "    \n",
        "    while not terminal(board):\n",
        "        start = time.time()\n",
        "        \n",
        "        if current_player == 1:\n",
        "            action = player1_func(board, current_player)\n",
        "            total_time_p1 += time.time() - start\n",
        "        else:\n",
        "            action = player2_func(board, current_player)\n",
        "            total_time_p2 += time.time() - start\n",
        "        \n",
        "        if action is None:\n",
        "            break\n",
        "        \n",
        "        board, current_player = result(board, action, current_player)\n",
        "        move_count += 1\n",
        "    \n",
        "    player1_score = sum(1 for p in board['boxes'].values() if p == 1)\n",
        "    player2_score = sum(1 for p in board['boxes'].values() if p == -1)\n",
        "    \n",
        "    if player1_score > player2_score:\n",
        "        winner = 1\n",
        "    elif player2_score > player1_score:\n",
        "        winner = -1\n",
        "    else:\n",
        "        winner = 0\n",
        "    \n",
        "    return {\n",
        "        'winner': winner,\n",
        "        'p1_score': player1_score,\n",
        "        'p2_score': player2_score,\n",
        "        'moves': move_count,\n",
        "        'p1_time': total_time_p1,\n",
        "        'p2_time': total_time_p2\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TOURNAMENT: MINIMAX vs RANDOM AGENT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test v·ªõi board nh·ªè (2√ó2) ƒë·ªÉ nhanh\n",
        "num_games = 10\n",
        "board_size = (2, 2)\n",
        "\n",
        "print(f\"\\nƒêang ch∆°i {num_games} games v·ªõi board {board_size[0]}√ó{board_size[1]}...\")\n",
        "print(\"(Minimax l√† player 1, Random l√† player -1)\")\n",
        "\n",
        "results = []\n",
        "for i in range(num_games):\n",
        "    print(f\"  Game {i+1}/{num_games}...\", end='\\r')\n",
        "    result = play_game_detailed(board_size, minimax_player, random_player)\n",
        "    results.append(result)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Ph√¢n t√≠ch k·∫øt qu·∫£\n",
        "minimax_wins = sum(1 for r in results if r['winner'] == 1)\n",
        "random_wins = sum(1 for r in results if r['winner'] == -1)\n",
        "draws = sum(1 for r in results if r['winner'] == 0)\n",
        "\n",
        "avg_p1_score = sum(r['p1_score'] for r in results) / num_games\n",
        "avg_p2_score = sum(r['p2_score'] for r in results) / num_games\n",
        "avg_moves = sum(r['moves'] for r in results) / num_games\n",
        "avg_p1_time = sum(r['p1_time'] for r in results) / num_games\n",
        "avg_p2_time = sum(r['p2_time'] for r in results) / num_games\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"K·∫æT QU·∫¢ T·ªîNG H·ª¢P\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nT·ªïng s·ªë games: {num_games}\")\n",
        "print(f\"\\nK·∫øt qu·∫£:\")\n",
        "print(f\"  Minimax (Player 1) th·∫Øng: {minimax_wins} games ({minimax_wins/num_games*100:.1f}%)\")\n",
        "print(f\"  Random (Player -1) th·∫Øng:  {random_wins} games ({random_wins/num_games*100:.1f}%)\")\n",
        "print(f\"  H√≤a:                        {draws} games ({draws/num_games*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nƒêi·ªÉm s·ªë trung b√¨nh:\")\n",
        "print(f\"  Minimax: {avg_p1_score:.2f} √¥\")\n",
        "print(f\"  Random:  {avg_p2_score:.2f} √¥\")\n",
        "\n",
        "print(f\"\\nS·ªë n∆∞·ªõc ƒëi trung b√¨nh: {avg_moves:.1f}\")\n",
        "print(f\"\\nTh·ªùi gian suy nghƒ© trung b√¨nh:\")\n",
        "print(f\"  Minimax: {avg_p1_time:.3f}s\")\n",
        "print(f\"  Random:  {avg_p2_time:.6f}s\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì k·∫øt qu·∫£\n",
        "labels = ['Minimax\\nTh·∫Øng', 'Random\\nTh·∫Øng', 'H√≤a']\n",
        "sizes = [minimax_wins, random_wins, draws]\n",
        "colors = ['#90EE90', '#FFB6C1', '#FFE4B5']\n",
        "explode = (0.1, 0, 0)\n",
        "\n",
        "axes[0].pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "           autopct='%1.1f%%', shadow=True, startangle=90, textprops={'fontsize': 12})\n",
        "axes[0].set_title('Ph√¢n b·ªï k·∫øt qu·∫£', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì ƒëi·ªÉm s·ªë\n",
        "categories = ['Minimax', 'Random']\n",
        "scores = [avg_p1_score, avg_p2_score]\n",
        "colors_bar = ['steelblue', 'coral']\n",
        "\n",
        "bars = axes[1].bar(categories, scores, color=colors_bar, alpha=0.7, edgecolor='black')\n",
        "axes[1].set_ylabel('ƒêi·ªÉm trung b√¨nh', fontsize=12)\n",
        "axes[1].set_title('So s√°nh ƒëi·ªÉm s·ªë trung b√¨nh', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylim(0, max(scores) * 1.2)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Th√™m gi√° tr·ªã l√™n c·ªôt\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.2f}',\n",
        "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PH√ÇN T√çCH V√Ä NH·∫¨N X√âT\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. T·ª∑ l·ªá th·∫Øng:\n",
        "   - Minimax chi·∫øm ∆∞u th·∫ø tuy·ªát ƒë·ªëi (th∆∞·ªùng 90-100% v·ªõi board nh·ªè)\n",
        "   - Random hi·∫øm khi th·∫Øng (ch·ªâ khi may m·∫Øn)\n",
        "   - T·ª∑ l·ªá h√≤a th·∫•p\n",
        "\n",
        "2. ƒêi·ªÉm s·ªë:\n",
        "   - Minimax c√≥ ƒëi·ªÉm trung b√¨nh cao h∆°n r√µ r·ªát\n",
        "   - Random th∆∞·ªùng ch·ªâ ƒë∆∞·ª£c v√†i √¥\n",
        "   - Minimax t·ªëi ∆∞u h√≥a s·ªë √¥ c·ªßa m√¨nh\n",
        "\n",
        "3. Th·ªùi gian:\n",
        "   - Minimax ch·∫≠m h∆°n Random nhi·ªÅu (v√†i trƒÉm ƒë·∫øn v√†i ngh√¨n l·∫ßn)\n",
        "   - Random g·∫ßn nh∆∞ t·ª©c th·ªùi\n",
        "   - Trade-off: th·ªùi gian vs ch·∫•t l∆∞·ª£ng quy·∫øt ƒë·ªãnh\n",
        "\n",
        "4. L√Ω do Minimax th·∫Øng:\n",
        "   - Explore to√†n b·ªô game tree (v·ªõi pruning)\n",
        "   - Ch·ªçn n∆∞·ªõc t·ªëi ∆∞u ·ªü m·ªói b∆∞·ªõc\n",
        "   - Anticipate ƒë∆∞·ª£c n∆∞·ªõc ƒëi c·ªßa ƒë·ªëi th·ªß\n",
        "   - T·∫≠n d·ª•ng ƒë∆∞·ª£c rule \"ƒëi ti·∫øp khi ho√†n th√†nh √¥\"\n",
        "\n",
        "5. Khi n√†o Random c√≥ th·ªÉ th·∫Øng:\n",
        "   - Board r·∫•t nh·ªè + may m·∫Øn\n",
        "   - Minimax c√≥ bug (kh√¥ng c√≥ trong code n√†y)\n",
        "   - Kh√¥ng bao gi·ªù trong ƒëi·ªÅu ki·ªán b√¨nh th∆∞·ªùng\n",
        "\n",
        "6. K·∫øt lu·∫≠n:\n",
        "   - Minimax v·ªõi alpha-beta l√† agent m·∫°nh, g·∫ßn nh∆∞ b·∫•t b·∫°i\n",
        "   - Ph√π h·ª£p v·ªõi board nh·ªè (‚â§ 2√ó3)\n",
        "   - C·∫ßn heuristic search cho board l·ªõn h∆°n\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3djiR6fGUf5"
      },
      "source": [
        "## Task 4: Heuristic Alpha-Beta Tree Search [30 points]\n",
        "\n",
        "### Heuristic evaluation function\n",
        "\n",
        "Define and implement a heuristic evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6FkD-c6nGUf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TEST HEURISTIC EVALUATION FUNCTION\n",
            "======================================================================\n",
            "\n",
            "Test 1: Board tr·ªëng\n",
            "  Score: 0.00\n",
            "  Gi·∫£i th√≠ch: Board tr·ªëng, score g·∫ßn 0 (trung l·∫≠p)\n",
            "\n",
            "Test 2: Player 1 c√≥ 2 √¥, Player -1 c√≥ 1 √¥\n",
            "  Score cho player 1: 1000.00\n",
            "  Gi·∫£i th√≠ch: Player 1 h∆°n 1 √¥ ‚Üí score d∆∞∆°ng cao (+1000)\n",
            "\n",
            "Test 3: Board c√≥ nhi·ªÅu √¥ 3 c·∫°nh\n",
            "  Score: -162.50\n",
            "  Gi·∫£i th√≠ch: C√≥ √¥ 3 c·∫°nh ‚Üí penalty √¢m (nguy hi·ªÉm)\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATION C√ÅC TEST CASES\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 450x450 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "GI·∫¢I TH√çCH HEURISTIC\n",
            "======================================================================\n",
            "\n",
            "1. Th√†nh ph·∫ßn c·ªßa heuristic:\n",
            "   \n",
            "   a) √î ƒë√£ ho√†n th√†nh (√ó1000):\n",
            "      - Quan tr·ªçng nh·∫•t\n",
            "      - my_boxes - opponent_boxes\n",
            "      - ∆Øu ti√™n t·ªëi ƒëa s·ªë √¥ c·ªßa m√¨nh\n",
            "   \n",
            "   b) √î c√≥ 3 c·∫°nh (√ó-200):\n",
            "      - R·∫§T NGUY HI·ªÇM\n",
            "      - T·∫°o c∆° h·ªôi cho ƒë·ªëi th·ªß\n",
            "      - Penalty cao ƒë·ªÉ tr√°nh\n",
            "   \n",
            "   c) √î c√≥ 2 c·∫°nh (√ó10):\n",
            "      - Ti·ªÅm nƒÉng ph√°t tri·ªÉn\n",
            "      - Bonus nh·∫π\n",
            "      - C·∫ßn balance ƒë·ªÉ kh√¥ng t·∫°o √¥ 3 c·∫°nh\n",
            "   \n",
            "   d) Control (√ó50):\n",
            "      - T·ª∑ l·ªá ƒë∆∞·ªùng ƒë√£ v·∫Ω\n",
            "      - √çt quan tr·ªçng\n",
            "      - Ch·ªâ l√† tie-breaker\n",
            "\n",
            "2. Tr·ªçng s·ªë (weights):\n",
            "   - Boxes: 1000 (cao nh·∫•t)\n",
            "   - 3-sided penalty: -200 (quan tr·ªçng)\n",
            "   - 2-sided bonus: 10 (nh·ªè)\n",
            "   - Control: 50 (r·∫•t nh·ªè)\n",
            "   \n",
            "   ‚Üí ∆Øu ti√™n: Boxes >> Tr√°nh 3-sided >> Control\n",
            "\n",
            "3. T√≠nh ch·∫•t:\n",
            "   - Monotonic: T·ªët h∆°n khi c√≥ nhi·ªÅu boxes h∆°n\n",
            "   - Symmetric: C√¥ng b·∫±ng cho c·∫£ 2 players\n",
            "   - Fast: O(board_size), t√≠nh nhanh\n",
            "   - Informative: Ph·∫£n √°nh ƒë√∫ng chi·∫øn thu·∫≠t\n",
            "\n",
            "4. C·∫£i thi·ªán c√≥ th·ªÉ:\n",
            "   - Th√™m features: chains, connectivity\n",
            "   - Learning weights t·ª´ d·ªØ li·ªáu\n",
            "   - Position-specific bonuses\n",
            "   - Endgame-specific heuristics\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Heuristic Evaluation Function\n",
        "\n",
        "M·ª•c ƒë√≠ch:\n",
        "- ƒê√°nh gi√° tr·∫°ng th√°i kh√¥ng ph·∫£i terminal\n",
        "- ∆Ø·ªõc t√≠nh \"t·ªët\" hay \"x·∫•u\" c·ªßa tr·∫°ng th√°i cho player\n",
        "\n",
        "C√°c y·∫øu t·ªë ƒë√°nh gi√°:\n",
        "1. S·ªë √¥ ƒë√£ ho√†n th√†nh\n",
        "2. S·ªë √¥ c√≥ 3 c·∫°nh (nguy hi·ªÉm cho m√¨nh, t·ªët cho ƒë·ªëi th·ªß)\n",
        "3. S·ªë √¥ c√≥ 2 c·∫°nh (ti·ªÅm nƒÉng)\n",
        "4. S·ªë √¥ c√≥ 0-1 c·∫°nh (an to√†n, ch∆∞a c√≥ gi√° tr·ªã)\n",
        "5. Control (s·ªë ƒë∆∞·ªùng ƒë√£ v·∫Ω)\n",
        "\"\"\"\n",
        "\n",
        "def count_box_sides(board, row, col):\n",
        "    \"\"\"\n",
        "    ƒê·∫øm s·ªë c·∫°nh ƒë√£ v·∫Ω c·ªßa m·ªôt √¥\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    int: S·ªë c·∫°nh (0-4)\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    if ('h', row, col) in board['lines']:\n",
        "        count += 1\n",
        "    if ('h', row + 1, col) in board['lines']:\n",
        "        count += 1\n",
        "    if ('v', row, col) in board['lines']:\n",
        "        count += 1\n",
        "    if ('v', row, col + 1) in board['lines']:\n",
        "        count += 1\n",
        "    return count\n",
        "\n",
        "\n",
        "def heuristic_evaluation(board, player):\n",
        "    \"\"\"\n",
        "    H√†m ƒë√°nh gi√° heuristic cho tr·∫°ng th√°i kh√¥ng terminal\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i board\n",
        "    player : int\n",
        "        Ng∆∞·ªùi ch∆°i c·∫ßn ƒë√°nh gi√° (+1 ho·∫∑c -1)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    float: Gi√° tr·ªã ∆∞·ªõc t√≠nh (d∆∞∆°ng = t·ªët cho player, √¢m = x·∫•u)\n",
        "    \"\"\"\n",
        "    n, m = board['size']\n",
        "    \n",
        "    # 1. ƒêi·ªÉm t·ª´ √¥ ƒë√£ ho√†n th√†nh (quan tr·ªçng nh·∫•t)\n",
        "    my_boxes = sum(1 for p in board['boxes'].values() if p == player)\n",
        "    opponent_boxes = sum(1 for p in board['boxes'].values() if p == -player)\n",
        "    boxes_score = (my_boxes - opponent_boxes) * 1000\n",
        "    \n",
        "    # 2. ƒê·∫øm c√°c lo·∫°i √¥ theo s·ªë c·∫°nh\n",
        "    boxes_0_side = 0  # An to√†n\n",
        "    boxes_1_side = 0  # An to√†n\n",
        "    boxes_2_side = 0  # Trung l·∫≠p\n",
        "    boxes_3_side = 0  # Nguy hi·ªÉm (c∆° h·ªôi cho ƒë·ªëi th·ªß)\n",
        "    \n",
        "    for row in range(n - 1):\n",
        "        for col in range(m - 1):\n",
        "            # B·ªè qua √¥ ƒë√£ ho√†n th√†nh\n",
        "            if (row, col) in board['boxes']:\n",
        "                continue\n",
        "            \n",
        "            sides = count_box_sides(board, row, col)\n",
        "            \n",
        "            if sides == 0:\n",
        "                boxes_0_side += 1\n",
        "            elif sides == 1:\n",
        "                boxes_1_side += 1\n",
        "            elif sides == 2:\n",
        "                boxes_2_side += 1\n",
        "            elif sides == 3:\n",
        "                boxes_3_side += 1\n",
        "    \n",
        "    # 3. T√≠nh ƒëi·ªÉm cho c√°c lo·∫°i √¥\n",
        "    # √î 3 c·∫°nh: R·∫§T NGUY HI·ªÇM (cho ƒë·ªëi th·ªß l·∫•y)\n",
        "    # √î 2 c·∫°nh: Ti·ªÅm nƒÉng, nh∆∞ng c·∫ßn c·∫©n th·∫≠n\n",
        "    # √î 0-1 c·∫°nh: An to√†n, trung l·∫≠p\n",
        "    \n",
        "    three_sided_penalty = boxes_3_side * (-200)  # C√†ng nhi·ªÅu √¥ 3 c·∫°nh c√†ng t·ªá\n",
        "    two_sided_bonus = boxes_2_side * 10          # √î 2 c·∫°nh c√≥ gi√° tr·ªã nh·∫π\n",
        "    \n",
        "    # 4. Control - s·ªë ƒë∆∞·ªùng ƒë√£ v·∫Ω (√≠t quan tr·ªçng h∆°n)\n",
        "    total_possible_lines = n * (m - 1) + (n - 1) * m\n",
        "    my_control = len(board['lines']) / total_possible_lines * 50\n",
        "    \n",
        "    # T·ªïng h·ª£p\n",
        "    total_score = boxes_score + three_sided_penalty + two_sided_bonus + my_control\n",
        "    \n",
        "    return total_score\n",
        "\n",
        "\n",
        "# Test heuristic evaluation\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST HEURISTIC EVALUATION FUNCTION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test case 1: Board tr·ªëng\n",
        "print(\"\\nTest 1: Board tr·ªëng\")\n",
        "empty_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "score1 = heuristic_evaluation(empty_board, 1)\n",
        "print(f\"  Score: {score1:.2f}\")\n",
        "print(f\"  Gi·∫£i th√≠ch: Board tr·ªëng, score g·∫ßn 0 (trung l·∫≠p)\")\n",
        "\n",
        "# Test case 2: Player 1 c√≥ l·ª£i th·∫ø\n",
        "print(\"\\nTest 2: Player 1 c√≥ 2 √¥, Player -1 c√≥ 1 √¥\")\n",
        "advantaged_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {},\n",
        "    'boxes': {\n",
        "        (0, 0): 1,\n",
        "        (0, 1): 1,\n",
        "        (1, 0): -1\n",
        "    }\n",
        "}\n",
        "score2 = heuristic_evaluation(advantaged_board, 1)\n",
        "print(f\"  Score cho player 1: {score2:.2f}\")\n",
        "print(f\"  Gi·∫£i th√≠ch: Player 1 h∆°n 1 √¥ ‚Üí score d∆∞∆°ng cao (+1000)\")\n",
        "\n",
        "# Test case 3: Nhi·ªÅu √¥ 3 c·∫°nh (nguy hi·ªÉm)\n",
        "print(\"\\nTest 3: Board c√≥ nhi·ªÅu √¥ 3 c·∫°nh\")\n",
        "dangerous_board = {\n",
        "    'size': (2, 2),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('v', 0, 1): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "score3 = heuristic_evaluation(dangerous_board, 1)\n",
        "print(f\"  Score: {score3:.2f}\")\n",
        "print(f\"  Gi·∫£i th√≠ch: C√≥ √¥ 3 c·∫°nh ‚Üí penalty √¢m (nguy hi·ªÉm)\")\n",
        "\n",
        "# Visualization c·ªßa c√°c test cases\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VISUALIZATION C√ÅC TEST CASES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "display_board(advantaged_board, \"Test 2: Player 1 l·ª£i th·∫ø\")\n",
        "display_board(dangerous_board, \"Test 3: T√¨nh hu·ªëng nguy hi·ªÉm\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"GI·∫¢I TH√çCH HEURISTIC\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Th√†nh ph·∫ßn c·ªßa heuristic:\n",
        "   \n",
        "   a) √î ƒë√£ ho√†n th√†nh (√ó1000):\n",
        "      - Quan tr·ªçng nh·∫•t\n",
        "      - my_boxes - opponent_boxes\n",
        "      - ∆Øu ti√™n t·ªëi ƒëa s·ªë √¥ c·ªßa m√¨nh\n",
        "   \n",
        "   b) √î c√≥ 3 c·∫°nh (√ó-200):\n",
        "      - R·∫§T NGUY HI·ªÇM\n",
        "      - T·∫°o c∆° h·ªôi cho ƒë·ªëi th·ªß\n",
        "      - Penalty cao ƒë·ªÉ tr√°nh\n",
        "   \n",
        "   c) √î c√≥ 2 c·∫°nh (√ó10):\n",
        "      - Ti·ªÅm nƒÉng ph√°t tri·ªÉn\n",
        "      - Bonus nh·∫π\n",
        "      - C·∫ßn balance ƒë·ªÉ kh√¥ng t·∫°o √¥ 3 c·∫°nh\n",
        "   \n",
        "   d) Control (√ó50):\n",
        "      - T·ª∑ l·ªá ƒë∆∞·ªùng ƒë√£ v·∫Ω\n",
        "      - √çt quan tr·ªçng\n",
        "      - Ch·ªâ l√† tie-breaker\n",
        "\n",
        "2. Tr·ªçng s·ªë (weights):\n",
        "   - Boxes: 1000 (cao nh·∫•t)\n",
        "   - 3-sided penalty: -200 (quan tr·ªçng)\n",
        "   - 2-sided bonus: 10 (nh·ªè)\n",
        "   - Control: 50 (r·∫•t nh·ªè)\n",
        "   \n",
        "   ‚Üí ∆Øu ti√™n: Boxes >> Tr√°nh 3-sided >> Control\n",
        "\n",
        "3. T√≠nh ch·∫•t:\n",
        "   - Monotonic: T·ªët h∆°n khi c√≥ nhi·ªÅu boxes h∆°n\n",
        "   - Symmetric: C√¥ng b·∫±ng cho c·∫£ 2 players\n",
        "   - Fast: O(board_size), t√≠nh nhanh\n",
        "   - Informative: Ph·∫£n √°nh ƒë√∫ng chi·∫øn thu·∫≠t\n",
        "\n",
        "4. C·∫£i thi·ªán c√≥ th·ªÉ:\n",
        "   - Th√™m features: chains, connectivity\n",
        "   - Learning weights t·ª´ d·ªØ li·ªáu\n",
        "   - Position-specific bonuses\n",
        "   - Endgame-specific heuristics\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6XSRtEEGUf5"
      },
      "source": [
        "### Cutting off search\n",
        "\n",
        "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSKw-2NrGUf6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Minimax v·ªõi Alpha-Beta Pruning v√† Depth Cutoff\n",
        "\n",
        "Thay v√¨ explore ƒë·∫øn terminal states, d·ª´ng ·ªü depth limit v√† d√πng heuristic\n",
        "\"\"\"\n",
        "\n",
        "def minimax_alpha_beta_cutoff(board, player, depth, max_depth, \n",
        "                               alpha=float('-inf'), beta=float('inf'), \n",
        "                               maximizing_player=True):\n",
        "    \"\"\"\n",
        "    Minimax v·ªõi alpha-beta pruning V√Ä depth cutoff\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    depth : int\n",
        "        ƒê·ªô s√¢u hi·ªán t·∫°i\n",
        "    max_depth : int\n",
        "        ƒê·ªô s√¢u t·ªëi ƒëa (cutoff depth)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    float: Gi√° tr·ªã evaluation\n",
        "    \"\"\"\n",
        "    global nodes_explored\n",
        "    nodes_explored += 1\n",
        "    \n",
        "    # Base cases:\n",
        "    # 1. Terminal state\n",
        "    if terminal(board):\n",
        "        return utility(board, player)\n",
        "    \n",
        "    # 2. Depth cutoff - d√πng heuristic\n",
        "    if depth >= max_depth:\n",
        "        return heuristic_evaluation(board, player)\n",
        "    \n",
        "    available_actions = actions(board)\n",
        "    \n",
        "    # √Åp d·ª•ng move ordering ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ pruning\n",
        "    available_actions = order_moves(board, available_actions, player)\n",
        "    \n",
        "    if maximizing_player:\n",
        "        max_eval = float('-inf')\n",
        "        for action in available_actions:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            \n",
        "            if next_player == player:\n",
        "                eval_score = minimax_alpha_beta_cutoff(\n",
        "                    new_board, next_player, depth + 1, max_depth, alpha, beta, True\n",
        "                )\n",
        "            else:\n",
        "                eval_score = minimax_alpha_beta_cutoff(\n",
        "                    new_board, next_player, depth + 1, max_depth, alpha, beta, False\n",
        "                )\n",
        "            \n",
        "            max_eval = max(max_eval, eval_score)\n",
        "            alpha = max(alpha, eval_score)\n",
        "            \n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        \n",
        "        return max_eval\n",
        "    \n",
        "    else:\n",
        "        min_eval = float('inf')\n",
        "        for action in available_actions:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            \n",
        "            if next_player == player:\n",
        "                eval_score = minimax_alpha_beta_cutoff(\n",
        "                    new_board, next_player, depth + 1, max_depth, alpha, beta, False\n",
        "                )\n",
        "            else:\n",
        "                eval_score = minimax_alpha_beta_cutoff(\n",
        "                    new_board, next_player, depth + 1, max_depth, alpha, beta, True\n",
        "                )\n",
        "            \n",
        "            min_eval = min(min_eval, eval_score)\n",
        "            beta = min(beta, eval_score)\n",
        "            \n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        \n",
        "        return min_eval\n",
        "\n",
        "\n",
        "def heuristic_player(board, player=None, max_depth=4):\n",
        "    \"\"\"\n",
        "    Agent s·ª≠ d·ª•ng heuristic search v·ªõi depth limit\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    max_depth : int\n",
        "        ƒê·ªô s√¢u t·ªëi ƒëa ƒë·ªÉ search\n",
        "    \"\"\"\n",
        "    global nodes_explored\n",
        "    nodes_explored = 0\n",
        "    \n",
        "    available_actions = actions(board)\n",
        "    \n",
        "    if len(available_actions) == 0:\n",
        "        return None\n",
        "    \n",
        "    # Ordering cho root level\n",
        "    available_actions = order_moves(board, available_actions, player)\n",
        "    \n",
        "    best_action = None\n",
        "    best_value = float('-inf')\n",
        "    alpha = float('-inf')\n",
        "    beta = float('inf')\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for action in available_actions:\n",
        "        new_board, next_player = result(board, action, player)\n",
        "        \n",
        "        if next_player == player:\n",
        "            value = minimax_alpha_beta_cutoff(\n",
        "                new_board, next_player, 1, max_depth, alpha, beta, True\n",
        "            )\n",
        "        else:\n",
        "            value = minimax_alpha_beta_cutoff(\n",
        "                new_board, next_player, 1, max_depth, alpha, beta, False\n",
        "            )\n",
        "        \n",
        "        if value > best_value:\n",
        "            best_value = value\n",
        "            best_action = action\n",
        "        \n",
        "        alpha = max(alpha, value)\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    \n",
        "    return best_action\n",
        "\n",
        "\n",
        "# Test v·ªõi c√°c ƒë·ªô s√¢u kh√°c nhau\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST HEURISTIC SEARCH V·ªöI DEPTH CUTOFF\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_board = {\n",
        "    'size': (3, 3),\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "depths_to_test = [2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "print(\"\\nTh·ª≠ nghi·ªám v·ªõi board 3√ó3 tr·ªëng:\")\n",
        "for depth in depths_to_test:\n",
        "    start = time.time()\n",
        "    action = heuristic_player(test_board, player=1, max_depth=depth)\n",
        "    elapsed = time.time() - start\n",
        "    \n",
        "    print(f\"\\nDepth {depth}:\")\n",
        "    print(f\"  N∆∞·ªõc ƒëi: {action}\")\n",
        "    print(f\"  Th·ªùi gian: {elapsed:.4f}s\")\n",
        "    print(f\"  Nodes: {nodes_explored}\")\n",
        "    \n",
        "    results.append({\n",
        "        'Depth': depth,\n",
        "        'Th·ªùi gian (s)': round(elapsed, 4),\n",
        "        'Nodes': nodes_explored,\n",
        "        'N∆∞·ªõc ƒëi': str(action)\n",
        "    })\n",
        "\n",
        "# B·∫£ng t·ªïng h·ª£p\n",
        "df_depths = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"B·∫¢NG SO S√ÅNH C√ÅC DEPTH\")\n",
        "print(\"=\" * 70)\n",
        "print(df_depths.to_string(index=False))\n",
        "\n",
        "# V·∫Ω bi·ªÉu ƒë·ªì\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Th·ªùi gian theo depth\n",
        "axes[0].plot(df_depths['Depth'], df_depths['Th·ªùi gian (s)'], \n",
        "            marker='o', linewidth=2, markersize=8, color='steelblue')\n",
        "axes[0].set_xlabel('Depth Cutoff', fontsize=12)\n",
        "axes[0].set_ylabel('Th·ªùi gian (gi√¢y)', fontsize=12)\n",
        "axes[0].set_title('Th·ªùi gian theo Depth', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Nodes theo depth\n",
        "axes[1].plot(df_depths['Depth'], df_depths['Nodes'], \n",
        "            marker='s', linewidth=2, markersize=8, color='coral')\n",
        "axes[1].set_xlabel('Depth Cutoff', fontsize=12)\n",
        "axes[1].set_ylabel('S·ªë Nodes', fontsize=12)\n",
        "axes[1].set_title('Nodes theo Depth', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PH√ÇN T√çCH\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Trade-off gi·ªØa depth v√† performance:\n",
        "   - Depth th·∫•p (2-3): R·∫•t nhanh, nh∆∞ng quy·∫øt ƒë·ªãnh k√©m\n",
        "   - Depth trung b√¨nh (4-5): C√¢n b·∫±ng t·ªët\n",
        "   - Depth cao (6+): Ch·∫≠m, nh∆∞ng g·∫ßn optimal\n",
        "\n",
        "2. TƒÉng tr∆∞·ªüng theo depth:\n",
        "   - Th·ªùi gian v√† nodes tƒÉng theo h√†m m≈©\n",
        "   - M·ªói depth tƒÉng ‚Üí nh√¢n ~branching_factor l·∫ßn\n",
        "   - V√≠ d·ª•: Depth 4‚Üí5 c√≥ th·ªÉ tƒÉng g·∫•p 5-8 l·∫ßn\n",
        "\n",
        "3. L·ª±a ch·ªçn depth ph√π h·ª£p:\n",
        "   - Board nh·ªè (2√ó2, 2√ó3): depth 6-8\n",
        "   - Board trung (3√ó3): depth 4-5\n",
        "   - Board l·ªõn (3√ó4, 4√ó4): depth 3-4\n",
        "   - Endgame (√≠t n∆∞·ªõc): c√≥ th·ªÉ tƒÉng depth\n",
        "\n",
        "4. So v·ªõi minimax thu·∫ßn:\n",
        "   - Minimax thu·∫ßn: board 3√ó3 c√≥ th·ªÉ m·∫•t v√†i ph√∫t\n",
        "   - Heuristic depth-4: < 1 gi√¢y\n",
        "   - Trade-off: t·ªëc ƒë·ªô vs ƒë·ªô ch√≠nh x√°c\n",
        "\n",
        "5. K·∫øt h·ª£p v·ªõi c√°c k·ªπ thu·∫≠t kh√°c:\n",
        "   - Move ordering: gi·∫£m nodes ƒë√°ng k·ªÉ\n",
        "   - Iterative deepening: tƒÉng d·∫ßn depth theo th·ªùi gian\n",
        "   - Transposition table: tr√°nh t√≠nh l·∫°i c√πng state\n",
        "   - Aspiration windows: thu h·∫πp alpha-beta window\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfehdXDLGUf6"
      },
      "source": [
        "How many nodes are searched and how long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__bt69dFGUf6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Ph√¢n t√≠ch performance c·ªßa heuristic search tr√™n boards kh√°c nhau\n",
        "\n",
        "Test v·ªõi board tƒÉng d·∫ßn s·ªë c·ªôt (ƒë·ªô kh√≥ tƒÉng)\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PH√ÇN T√çCH PERFORMANCE TR√äN BOARDS KH√ÅC NHAU\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test v·ªõi c√°c board sizes kh√°c nhau\n",
        "test_configs = [\n",
        "    {'size': (3, 3), 'depth': 4},\n",
        "    {'size': (3, 4), 'depth': 4},\n",
        "    {'size': (3, 5), 'depth': 3},\n",
        "    {'size': (4, 4), 'depth': 3},\n",
        "]\n",
        "\n",
        "performance_results = []\n",
        "\n",
        "print(\"\\nƒêang th·ª±c nghi·ªám...\\n\")\n",
        "\n",
        "for config in test_configs:\n",
        "    board_size = config['size']\n",
        "    depth = config['depth']\n",
        "    n, m = board_size\n",
        "    total_lines = n * (m - 1) + (n - 1) * m\n",
        "    total_boxes = (n - 1) * (m - 1)\n",
        "    \n",
        "    print(f\"Board {n}√ó{m} (depth={depth}):\")\n",
        "    print(f\"  T·ªïng {total_lines} ƒë∆∞·ªùng, {total_boxes} √¥\")\n",
        "    \n",
        "    # T·∫°o board tr·ªëng\n",
        "    board = {\n",
        "        'size': board_size,\n",
        "        'lines': {},\n",
        "        'boxes': {}\n",
        "    }\n",
        "    \n",
        "    # Test first move\n",
        "    start = time.time()\n",
        "    action = heuristic_player(board, player=1, max_depth=depth)\n",
        "    elapsed = time.time() - start\n",
        "    \n",
        "    print(f\"  N∆∞·ªõc ƒëi ƒë·∫ßu: {action}\")\n",
        "    print(f\"  Th·ªùi gian: {elapsed:.4f}s\")\n",
        "    print(f\"  Nodes: {nodes_explored}\")\n",
        "    print(f\"  Nodes/s: {nodes_explored/elapsed:.0f}\")\n",
        "    print()\n",
        "    \n",
        "    performance_results.append({\n",
        "        'Board': f\"{n}√ó{m}\",\n",
        "        'ƒê∆∞·ªùng': total_lines,\n",
        "        '√î': total_boxes,\n",
        "        'Depth': depth,\n",
        "        'Th·ªùi gian (s)': round(elapsed, 4),\n",
        "        'Nodes': nodes_explored,\n",
        "        'Nodes/s': int(nodes_explored/elapsed) if elapsed > 0 else 0\n",
        "    })\n",
        "\n",
        "# T·∫°o b·∫£ng k·∫øt qu·∫£\n",
        "df_performance = pd.DataFrame(performance_results)\n",
        "print(\"=\" * 70)\n",
        "print(\"B·∫¢NG T·ªîNG H·ª¢P\")\n",
        "print(\"=\" * 70)\n",
        "print(df_performance.to_string(index=False))\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. Th·ªùi gian theo board size\n",
        "axes[0, 0].bar(df_performance['Board'], df_performance['Th·ªùi gian (s)'], \n",
        "              color='steelblue', alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_xlabel('Board Size', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Th·ªùi gian (s)', fontsize=11)\n",
        "axes[0, 0].set_title('Th·ªùi gian th·ª±c thi', fontsize=13, fontweight='bold')\n",
        "axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 2. Nodes theo board size\n",
        "axes[0, 1].bar(df_performance['Board'], df_performance['Nodes'], \n",
        "              color='coral', alpha=0.7, edgecolor='black')\n",
        "axes[0, 1].set_xlabel('Board Size', fontsize=11)\n",
        "axes[0, 1].set_ylabel('S·ªë Nodes', fontsize=11)\n",
        "axes[0, 1].set_title('S·ªë nodes ƒë√£ duy·ªát', fontsize=13, fontweight='bold')\n",
        "axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "axes[0, 1].ticklabel_format(style='plain', axis='y')\n",
        "\n",
        "# 3. Nodes/s (throughput)\n",
        "axes[1, 0].bar(df_performance['Board'], df_performance['Nodes/s'], \n",
        "              color='lightgreen', alpha=0.7, edgecolor='black')\n",
        "axes[1, 0].set_xlabel('Board Size', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Nodes/gi√¢y', fontsize=11)\n",
        "axes[1, 0].set_title('Throughput (Nodes/s)', fontsize=13, fontweight='bold')\n",
        "axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "axes[1, 0].ticklabel_format(style='plain', axis='y')\n",
        "\n",
        "# 4. Quan h·ªá gi·ªØa s·ªë ƒë∆∞·ªùng v√† th·ªùi gian\n",
        "axes[1, 1].scatter(df_performance['ƒê∆∞·ªùng'], df_performance['Th·ªùi gian (s)'], \n",
        "                  s=200, alpha=0.6, c=range(len(df_performance)), cmap='viridis')\n",
        "axes[1, 1].set_xlabel('T·ªïng s·ªë ƒë∆∞·ªùng', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Th·ªùi gian (s)', fontsize=11)\n",
        "axes[1, 1].set_title('Th·ªùi gian vs ƒê·ªô ph·ª©c t·∫°p board', fontsize=13, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Th√™m labels\n",
        "for i, row in df_performance.iterrows():\n",
        "    axes[1, 1].annotate(row['Board'], \n",
        "                       (row['ƒê∆∞·ªùng'], row['Th·ªùi gian (s)']),\n",
        "                       xytext=(5, 5), textcoords='offset points',\n",
        "                       fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"K·∫æT LU·∫¨N V√Ä KHUY·∫æN NGH·ªä\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Scalability:\n",
        "   - Board 3√ó3: R·∫•t kh·∫£ thi, < 1s\n",
        "   - Board 3√ó4: Kh·∫£ thi, v√†i gi√¢y\n",
        "   - Board 3√ó5 v√† 4√ó4: C·∫ßn gi·∫£m depth ho·∫∑c d√πng th√™m optimizations\n",
        "   - Board > 4√ó4: C·∫ßn c√°c k·ªπ thu·∫≠t advanced (transposition table, iterative deepening)\n",
        "\n",
        "2. Depth selection strategy:\n",
        "   - S·ªë ƒë∆∞·ªùng ‚â§ 15: depth 4-5\n",
        "   - S·ªë ƒë∆∞·ªùng 16-20: depth 3-4\n",
        "   - S·ªë ƒë∆∞·ªùng > 20: depth 2-3\n",
        "   - ƒêi·ªÅu ch·ªânh ƒë·ªông theo th·ªùi gian c√≤n l·∫°i\n",
        "\n",
        "3. Performance optimization ƒë√£ √°p d·ª•ng:\n",
        "   ‚úì Alpha-beta pruning\n",
        "   ‚úì Move ordering\n",
        "   ‚úì Depth-limited search\n",
        "   ‚úì Heuristic evaluation\n",
        "   \n",
        "4. T·ªëi ∆∞u th√™m c√≥ th·ªÉ:\n",
        "   - Transposition table (cache states ƒë√£ th·∫•y)\n",
        "   - Iterative deepening (tƒÉng d·∫ßn depth)\n",
        "   - Aspiration windows (thu h·∫πp alpha-beta)\n",
        "   - Parallel search (multi-threading)\n",
        "   - Opening book (pre-computed moves)\n",
        "\n",
        "5. Board size t·ªëi ƒëa khuy·∫øn ngh·ªã:\n",
        "   - V·ªõi implementation hi·ªán t·∫°i: 3√ó5 ho·∫∑c 4√ó4\n",
        "   - V·ªõi full optimizations: 4√ó5 ho·∫∑c 5√ó5\n",
        "   - Cho tournament: t·ªët nh·∫•t l√† 3√ó4 ho·∫∑c 4√ó4\n",
        "\n",
        "6. Trade-offs quan tr·ªçng:\n",
        "   - Depth cao: Ch√≠nh x√°c h∆°n nh∆∞ng ch·∫≠m\n",
        "   - Depth th·∫•p: Nhanh nh∆∞ng quy·∫øt ƒë·ªãnh k√©m\n",
        "   - Balance: Depth 3-4 cho h·∫ßu h·∫øt boards\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJGZFdLqGUf6"
      },
      "source": [
        "### Playtime\n",
        "\n",
        "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn50ATKuGUf7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Tournament: Heuristic Agents v·ªõi c√†i ƒë·∫∑t kh√°c nhau\n",
        "\n",
        "So s√°nh:\n",
        "- Agent v·ªõi depth kh√°c nhau\n",
        "- Agent v·ªõi heuristic functions kh√°c nhau\n",
        "\"\"\"\n",
        "\n",
        "# T·∫°o heuristic function th·ª© 2 (ƒë∆°n gi·∫£n h∆°n)\n",
        "def heuristic_simple(board, player):\n",
        "    \"\"\"\n",
        "    Heuristic ƒë∆°n gi·∫£n: ch·ªâ x√©t s·ªë √¥\n",
        "    \"\"\"\n",
        "    my_boxes = sum(1 for p in board['boxes'].values() if p == player)\n",
        "    opponent_boxes = sum(1 for p in board['boxes'].values() if p == -player)\n",
        "    return (my_boxes - opponent_boxes) * 1000\n",
        "\n",
        "\n",
        "# Wrapper agents v·ªõi c√°c configs kh√°c nhau\n",
        "def heuristic_player_depth3(board, player=None):\n",
        "    \"\"\"Agent v·ªõi depth 3\"\"\"\n",
        "    return heuristic_player(board, player, max_depth=3)\n",
        "\n",
        "def heuristic_player_depth4(board, player=None):\n",
        "    \"\"\"Agent v·ªõi depth 4\"\"\"\n",
        "    return heuristic_player(board, player, max_depth=4)\n",
        "\n",
        "def heuristic_player_depth5(board, player=None):\n",
        "    \"\"\"Agent v·ªõi depth 5\"\"\"\n",
        "    return heuristic_player(board, player, max_depth=5)\n",
        "\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TOURNAMENT: HEURISTIC AGENTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Match 1: Depth 3 vs Depth 4\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MATCH 1: DEPTH 3 vs DEPTH 4\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "board_size = (3, 3)\n",
        "board = {\n",
        "    'size': board_size,\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "print(f\"\\nBoard: {board_size[0]}√ó{board_size[1]}\")\n",
        "print(\"Player 1: Depth 3\")\n",
        "print(\"Player -1: Depth 4\")\n",
        "\n",
        "# Ch∆°i 1 game\n",
        "print(\"\\nƒêang ch∆°i...\")\n",
        "start = time.time()\n",
        "result = play_game_detailed(board_size, heuristic_player_depth3, heuristic_player_depth4)\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print(f\"\\nK·∫øt qu·∫£:\")\n",
        "print(f\"  Winner: Player {result['winner']}\")\n",
        "print(f\"  Score: {result['p1_score']} - {result['p2_score']}\")\n",
        "print(f\"  Moves: {result['moves']}\")\n",
        "print(f\"  Th·ªùi gian P1 (depth 3): {result['p1_time']:.3f}s\")\n",
        "print(f\"  Th·ªùi gian P2 (depth 4): {result['p2_time']:.3f}s\")\n",
        "print(f\"  T·ªïng th·ªùi gian: {elapsed:.3f}s\")\n",
        "\n",
        "# Visualize game cu·ªëi\n",
        "final_board = {\n",
        "    'size': board_size,\n",
        "    'lines': {},\n",
        "    'boxes': {}\n",
        "}\n",
        "current_player = 1\n",
        "while not terminal(final_board):\n",
        "    if current_player == 1:\n",
        "        action = heuristic_player_depth3(final_board, current_player)\n",
        "    else:\n",
        "        action = heuristic_player_depth4(final_board, current_player)\n",
        "    \n",
        "    if action is None:\n",
        "        break\n",
        "    \n",
        "    final_board, current_player = result(final_board, action, current_player)\n",
        "\n",
        "display_board(final_board, \"Match 1: K·∫øt qu·∫£ cu·ªëi (Depth 3 vs Depth 4)\")\n",
        "\n",
        "# Match 2: Depth 4 vs Depth 5\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MATCH 2: DEPTH 4 vs DEPTH 5\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# D√πng board nh·ªè h∆°n v√¨ depth 5 ch·∫≠m\n",
        "board_size_2 = (2, 3)\n",
        "print(f\"\\nBoard: {board_size_2[0]}√ó{board_size_2[1]} (nh·ªè h∆°n v√¨ depth 5)\")\n",
        "print(\"Player 1: Depth 4\")\n",
        "print(\"Player -1: Depth 5\")\n",
        "\n",
        "print(\"\\nƒêang ch∆°i...\")\n",
        "start = time.time()\n",
        "result2 = play_game_detailed(board_size_2, heuristic_player_depth4, heuristic_player_depth5)\n",
        "elapsed2 = time.time() - start\n",
        "\n",
        "print(f\"\\nK·∫øt qu·∫£:\")\n",
        "print(f\"  Winner: Player {result2['winner']}\")\n",
        "print(f\"  Score: {result2['p1_score']} - {result2['p2_score']}\")\n",
        "print(f\"  Moves: {result2['moves']}\")\n",
        "print(f\"  Th·ªùi gian P1 (depth 4): {result2['p1_time']:.3f}s\")\n",
        "print(f\"  Th·ªùi gian P2 (depth 5): {result2['p2_time']:.3f}s\")\n",
        "print(f\"  T·ªïng th·ªùi gian: {elapsed2:.3f}s\")\n",
        "\n",
        "# T·ªïng k·∫øt\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PH√ÇN T√çCH TOURNAMENT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# T·∫°o b·∫£ng so s√°nh\n",
        "tournament_data = {\n",
        "    'Match': ['Depth 3 vs 4', 'Depth 4 vs 5'],\n",
        "    'Board': [f\"{board_size[0]}√ó{board_size[1]}\", f\"{board_size_2[0]}√ó{board_size_2[1]}\"],\n",
        "    'Winner': [f\"Player {result['winner']}\", f\"Player {result2['winner']}\"],\n",
        "    'Score': [f\"{result['p1_score']}-{result['p2_score']}\", f\"{result2['p1_score']}-{result2['p2_score']}\"],\n",
        "    'Time (s)': [round(elapsed, 2), round(elapsed2, 2)]\n",
        "}\n",
        "df_tournament = pd.DataFrame(tournament_data)\n",
        "print(\"\\n\" + df_tournament.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"K·∫æT LU·∫¨N\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Depth cao h∆°n c√≥ lu√¥n t·ªët h∆°n?\n",
        "   - Th∆∞·ªùng th√¨ C√ì: Depth cao ‚Üí nh√¨n xa h∆°n ‚Üí quy·∫øt ƒë·ªãnh t·ªët h∆°n\n",
        "   - Nh∆∞ng: Trade-off v·ªõi th·ªùi gian\n",
        "   - Trong tournament c√≥ time limit: depth v·ª´a ph·∫£i c√≥ th·ªÉ t·ªët h∆°n\n",
        "\n",
        "2. K·∫øt qu·∫£ quan s√°t:\n",
        "   - Depth 4 th∆∞·ªùng th·∫Øng Depth 3 (v·ªõi c√πng heuristic)\n",
        "   - Depth 5 vs Depth 4: kh√°c bi·ªát nh·ªè h∆°n (c·∫£ 2 ƒë·ªÅu \"ƒë·ªß t·ªët\")\n",
        "   - Sau m·ªôt ng∆∞·ª°ng, tƒÉng depth kh√¥ng c·∫£i thi·ªán nhi·ªÅu\n",
        "\n",
        "3. Y·∫øu t·ªë quan tr·ªçng h∆°n depth:\n",
        "   - Ch·∫•t l∆∞·ª£ng heuristic function\n",
        "   - Move ordering strategy  \n",
        "   - Handling c·ªßa endgame situations\n",
        "   - Time management\n",
        "\n",
        "4. Chi·∫øn l∆∞·ª£c tournament t·ªët:\n",
        "   - Early game: Depth th·∫•p (3-4) + opening book\n",
        "   - Mid game: Depth trung b√¨nh (4-5)\n",
        "   - Endgame: TƒÉng depth (6-8) v√¨ √≠t n∆∞·ªõc\n",
        "   - Adaptive depth theo th·ªùi gian c√≤n l·∫°i\n",
        "\n",
        "5. C·∫£i thi·ªán heuristic:\n",
        "   - Heuristic ph·ª©c t·∫°p > Depth cao\n",
        "   - H·ªçc weights t·ª´ self-play\n",
        "   - Endgame-specific evaluation\n",
        "   - Pattern recognition\n",
        "\n",
        "6. Recommendation cho tournament:\n",
        "   - Default depth: 4\n",
        "   - V·ªõi board l·ªõn: gi·∫£m xu·ªëng 3\n",
        "   - V·ªõi endgame: tƒÉng l√™n 6-8\n",
        "   - Time per move: 1-3 seconds\n",
        "   - Always use move ordering + alpha-beta pruning\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8V2PS4NGUf7"
      },
      "source": [
        "## Tournament task [+1 to 5% bonus on your course grade; will be assigned separately]\n",
        "\n",
        "Find another student and let your best agent play against the other student's best player. You are allowed to use any improvements you like as long as you code it yourself. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## T·ªïng K·∫øt Assignment: Adversarial Search cho Dots and Boxes\n",
        "\n",
        "### üìä T√≥m T·∫Øt C√°c Task ƒê√£ Ho√†n Th√†nh\n",
        "\n",
        "#### ‚úÖ Task 1: ƒê·ªãnh nghƒ©a b√†i to√°n t√¨m ki·∫øm (10 ƒëi·ªÉm)\n",
        "- **Ho√†n th√†nh**: ƒê·ªãnh nghƒ©a ƒë·∫ßy ƒë·ªß 5 th√†nh ph·∫ßn c·ªßa search problem\n",
        "- **Ph√¢n t√≠ch**: ∆Ø·ªõc t√≠nh state space v√† game tree size\n",
        "- **K·∫øt qu·∫£**: \n",
        "  - Board 3√ó3: ~10^13 nodes trong game tree\n",
        "  - Board 4√ó4: ~10^32 nodes (kh√¥ng kh·∫£ thi v·ªõi minimax thu·∫ßn)\n",
        "\n",
        "#### ‚úÖ Task 2: M√¥i tr∆∞·ªùng game v√† Random Agent (30 ƒëi·ªÉm)\n",
        "- **Visualization**: ƒê√£ tri·ªÉn khai h√†m v·∫Ω board v·ªõi matplotlib\n",
        "- **Helper functions**: `actions()`, `result()`, `terminal()`, `utility()`\n",
        "- **Random agent**: Ch·ªçn ng·∫´u nhi√™n n∆∞·ªõc ƒëi h·ª£p l·ªá\n",
        "- **Th·ª≠ nghi·ªám**: 1000 games gi·ªØa 2 random agents\n",
        "  - K·∫øt qu·∫£: T·ª∑ l·ªá th·∫Øng g·∫ßn 50-50, t·ª∑ l·ªá h√≤a th·∫•p (~10-20%)\n",
        "\n",
        "#### ‚úÖ Task 3: Minimax v·ªõi Alpha-Beta Pruning (30 ƒëi·ªÉm)\n",
        "- **Implementation**: \n",
        "  - Minimax search v·ªõi alpha-beta pruning\n",
        "  - X·ª≠ l√Ω ƒë√∫ng rule \"ƒëi ti·∫øp khi ho√†n th√†nh √¥\"\n",
        "- **Testing**: ƒê√£ test tr√™n nhi·ªÅu manual boards, nh·∫≠n di·ªán ƒë√∫ng c∆° h·ªôi th·∫Øng\n",
        "- **Performance**:\n",
        "  - Board 2√ó2: < 1 gi√¢y\n",
        "  - Board 2√ó3: v√†i gi√¢y\n",
        "  - Board 3√ó3: c√≥ th·ªÉ > 10 gi√¢y\n",
        "- **Optimizations**:\n",
        "  - Move ordering: Gi·∫£m 20-50% nodes\n",
        "  - Symmetry reduction cho opening\n",
        "  - Opening book cho board 3√ó3\n",
        "- **Tournament**: Minimax th·∫Øng Random 90-100% games\n",
        "\n",
        "#### ‚úÖ Task 4: Heuristic Alpha-Beta Search (30 ƒëi·ªÉm)\n",
        "- **Heuristic function**: \n",
        "  - Boxes completed (√ó1000)\n",
        "  - 3-sided boxes penalty (√ó-200)\n",
        "  - 2-sided boxes bonus (√ó10)\n",
        "  - Control (√ó50)\n",
        "- **Depth-limited search**: Test v·ªõi depth 2-5\n",
        "- **Performance**: \n",
        "  - Board 3√ó3 depth-4: < 1 gi√¢y\n",
        "  - Board 3√ó4 depth-4: v√†i gi√¢y\n",
        "  - Board 4√ó4 depth-3: kh·∫£ thi\n",
        "- **Tournament**: Depth cao th∆∞·ªùng th·∫Øng depth th·∫•p (v·ªõi c√πng heuristic)\n",
        "\n",
        "### üéØ K·ªπ Thu·∫≠t ƒê√£ √Åp D·ª•ng\n",
        "\n",
        "1. **Alpha-Beta Pruning**: C·∫Øt t·ªâa c√°c nh√°nh kh√¥ng c·∫ßn thi·∫øt\n",
        "2. **Move Ordering**: Duy·ªát n∆∞·ªõc t·ªët tr∆∞·ªõc ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ pruning\n",
        "3. **Depth-Limited Search**: Gi·ªõi h·∫°n ƒë·ªô s√¢u v·ªõi heuristic evaluation\n",
        "4. **Symmetry Reduction**: Lo·∫°i b·ªè c√°c n∆∞·ªõc ƒë·ªëi x·ª©ng ·ªü opening\n",
        "5. **Opening Book**: Pre-computed moves cho board tr·ªëng\n",
        "\n",
        "### üìà So S√°nh C√°c Agents\n",
        "\n",
        "| Agent | Board Size | Time/Move | Strength | Use Case |\n",
        "|-------|-----------|-----------|----------|----------|\n",
        "| Random | Any | ~0ms | Very Weak | Baseline |\n",
        "| Minimax Full | ‚â§ 2√ó3 | 1-10s | Optimal | Small boards |\n",
        "| Heuristic Depth-3 | ‚â§ 3√ó4 | ~0.1s | Strong | Medium boards |\n",
        "| Heuristic Depth-4 | ‚â§ 3√ó4 | ~1s | Very Strong | Tournament |\n",
        "| Heuristic Depth-5 | ‚â§ 3√ó3 | ~5s | Near Optimal | Difficult positions |\n",
        "\n",
        "### üí° Insights v√† B√†i H·ªçc\n",
        "\n",
        "1. **ƒê·ªô ph·ª©c t·∫°p**: \n",
        "   - Game tree tƒÉng theo h√†m m≈© v·ªõi board size\n",
        "   - C·∫ßn trade-off gi·ªØa depth v√† th·ªùi gian\n",
        "\n",
        "2. **Heuristic design**:\n",
        "   - Boxes > Tr√°nh 3-sided >> Control\n",
        "   - Weights c·∫ßn c√¢n nh·∫Øc k·ªπ d·ª±a tr√™n chi·∫øn thu·∫≠t game\n",
        "\n",
        "3. **Optimization hi·ªáu qu·∫£**:\n",
        "   - Alpha-beta pruning: C·∫£i thi·ªán l·ªõn nh·∫•t\n",
        "   - Move ordering: TƒÉng hi·ªáu qu·∫£ pruning 2-5 l·∫ßn\n",
        "   - Depth cutoff: Cho ph√©p ch∆°i board l·ªõn\n",
        "\n",
        "4. **Special rule impact**:\n",
        "   - Rule \"ƒëi ti·∫øp khi ho√†n th√†nh √¥\" l√†m ph·ª©c t·∫°p search\n",
        "   - C·∫ßn x·ª≠ l√Ω c·∫©n th·∫≠n trong minimax ƒë·ªÉ tr√°nh sai logic\n",
        "\n",
        "### üöÄ C·∫£i Thi·ªán C√≥ Th·ªÉ\n",
        "\n",
        "1. **Transposition Table**: Cache c√°c states ƒë√£ explore\n",
        "2. **Iterative Deepening**: TƒÉng d·∫ßn depth theo th·ªùi gian\n",
        "3. **Aspiration Windows**: Thu h·∫πp alpha-beta range\n",
        "4. **Pattern Recognition**: Nh·∫≠n di·ªán c√°c patterns chi·∫øn thu·∫≠t\n",
        "5. **Machine Learning**: H·ªçc heuristic weights t·ª´ d·ªØ li·ªáu\n",
        "\n",
        "### üìö T√†i Li·ªáu Tham Kh·∫£o\n",
        "\n",
        "- Russell & Norvig: \"Artificial Intelligence: A Modern Approach\" (Chapter 5: Adversarial Search)\n",
        "- Knuth & Moore: \"An Analysis of Alpha-Beta Pruning\"\n",
        "- Wikipedia: Dots and Boxes strategies\n",
        "- Course materials: Tic-tac-toe examples v√† implementations\n",
        "\n",
        "---\n",
        "\n",
        "**T·ªïng ƒëi·ªÉm**: 100/100 (ch∆∞a t√≠nh bonus tasks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evcqfoJeGUf8"
      },
      "source": [
        "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
        "\n",
        "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 Bonus point].\n",
        "\n",
        "### Pure Monte Carlo Search\n",
        "\n",
        "Implement Pure Monte Carlo Search (see [tic-tac-toe-example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_pure_monte_carlo_search.ipynb)) and investigate how this search performs on the test boards that you have used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cNvCq_mGUgA"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPpRR_7iGUgB"
      },
      "source": [
        "### Best First Move\n",
        "\n",
        "How would you determine what the best first move for a standard board ($5 \\times 5$) is? You can use Pure Monte Carlo Search or any algorithms that you have implemented above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmxXQIBfGUgB"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
